{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4994ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 22:06:24,260 - INFO - Starting debug tests...\n",
      "2025-04-13 22:06:24,262 - INFO - Testing Kafka connection to localhost:29092\n",
      "2025-04-13 22:06:24,263 - INFO - Creating test consumer...\n",
      "2025-04-13 22:06:24,266 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 22:06:24,267 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:24,268 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:24,269 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: connecting to localhost:29092 [('127.0.0.1', 29092) IPv4]\n",
      "2025-04-13 22:06:24,271 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:24,271 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:24,275 - WARNING - No node available during check_version; sleeping 0.04 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 22:06:24,323 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 22:06:24,323 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:24,324 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:24,325 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: connecting to localhost:29092 [('127.0.0.1', 29092) IPv4]\n",
      "2025-04-13 22:06:24,325 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:24,326 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:24,327 - WARNING - No node available during check_version; sleeping 0.11 secs\n",
      "2025-04-13 22:06:24,440 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 22:06:24,440 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:24,441 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:24,442 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: connecting to localhost:29092 [('127.0.0.1', 29092) IPv4]\n",
      "2025-04-13 22:06:24,443 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:24,443 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:24,444 - WARNING - No node available during check_version; sleeping 0.23 secs\n",
      "2025-04-13 22:06:24,675 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 22:06:24,676 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:24,676 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:24,677 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: connecting to localhost:29092 [('127.0.0.1', 29092) IPv4]\n",
      "2025-04-13 22:06:24,678 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:24,678 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:24,679 - WARNING - No node available during check_version; sleeping 0.42 secs\n",
      "2025-04-13 22:06:25,097 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 22:06:25,097 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:25,098 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:25,099 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: connecting to localhost:29092 [('127.0.0.1', 29092) IPv4]\n",
      "2025-04-13 22:06:25,099 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:25,100 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:25,100 - WARNING - No node available during check_version; sleeping 0.67 secs\n",
      "2025-04-13 22:06:25,773 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 22:06:25,773 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:25,774 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:25,775 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: connecting to localhost:29092 [('127.0.0.1', 29092) IPv4]\n",
      "2025-04-13 22:06:25,776 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:25,776 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:25,777 - WARNING - No node available during check_version; sleeping 0.49 secs\n",
      "2025-04-13 22:06:26,266 - ERROR - Kafka connection failed: NoBrokersAvailable\n",
      "2025-04-13 22:06:26,267 - INFO - Testing PostgreSQL connection to localhost:5432/voting_db\n",
      "2025-04-13 22:06:26,268 - ERROR - PostgreSQL connection failed: connection to server at \"localhost\" (::1), port 5432 failed: Connection refused\n",
      "\tIs the server running on that host and accepting TCP/IP connections?\n",
      "connection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused\n",
      "\tIs the server running on that host and accepting TCP/IP connections?\n",
      "\n",
      "2025-04-13 22:06:26,269 - INFO - DLT version: 1.9.0\n",
      "2025-04-13 22:06:26,298 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 22:06:26,299 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:26,299 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:26,300 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: connecting to localhost:29092 [('127.0.0.1', 29092) IPv4]\n",
      "2025-04-13 22:06:26,301 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:26,301 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:26,302 - WARNING - No node available during check_version; sleeping 0.04 secs\n",
      "2025-04-13 22:06:26,346 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 22:06:26,346 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:26,347 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:26,348 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: connecting to localhost:29092 [('127.0.0.1', 29092) IPv4]\n",
      "2025-04-13 22:06:26,348 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:26,349 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:26,349 - WARNING - No node available during check_version; sleeping 0.08 secs\n",
      "2025-04-13 22:06:26,432 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 22:06:26,432 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:26,433 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:26,434 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: connecting to localhost:29092 [('127.0.0.1', 29092) IPv4]\n",
      "2025-04-13 22:06:26,434 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:26,434 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:26,435 - WARNING - No node available during check_version; sleeping 0.19 secs\n",
      "2025-04-13 22:06:26,622 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 22:06:26,623 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:26,624 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:26,624 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: connecting to localhost:29092 [('127.0.0.1', 29092) IPv4]\n",
      "2025-04-13 22:06:26,625 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:26,626 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:26,626 - WARNING - No node available during check_version; sleeping 0.47 secs\n",
      "2025-04-13 22:06:27,098 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 22:06:27,099 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:27,100 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:27,100 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: connecting to localhost:29092 [('127.0.0.1', 29092) IPv4]\n",
      "2025-04-13 22:06:27,101 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:27,102 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:27,103 - WARNING - No node available during check_version; sleeping 0.82 secs\n",
      "2025-04-13 22:06:27,926 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 22:06:27,927 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:27,928 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:27,928 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: connecting to localhost:29092 [('127.0.0.1', 29092) IPv4]\n",
      "2025-04-13 22:06:27,929 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:27,930 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:27,930 - WARNING - No node available during check_version; sleeping 0.37 secs\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 252\u001b[39m\n\u001b[32m    249\u001b[39m         logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDebug container alive - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/10 minutes\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 237\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    235\u001b[39m voter_topic_ok = test_voter_topic() \u001b[38;5;28;01mif\u001b[39;00m kafka_ok \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    236\u001b[39m postgres_ok = test_postgres_connection()\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m dlt_ok = \u001b[43mtest_dlt_installation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m----- TEST RESULTS -----\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    240\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKafka Connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m✅\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mkafka_ok\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33m❌\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 210\u001b[39m, in \u001b[36mtest_dlt_installation\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    202\u001b[39m destination_type, destination_config = get_destination_config()\n\u001b[32m    203\u001b[39m pipeline = dlt.pipeline(\n\u001b[32m    204\u001b[39m     pipeline_name=pipeline_name,\n\u001b[32m    205\u001b[39m     destination=postgres(destination_config),\n\u001b[32m    206\u001b[39m     dataset_name=\u001b[33m'\u001b[39m\u001b[33mpublic\u001b[39m\u001b[33m'\u001b[39m,  \u001b[38;5;66;03m# Use 'public' schema or whatever schema your tables are in\u001b[39;00m\n\u001b[32m    207\u001b[39m     dev_mode=\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# This forces DLT to recreate all internal state tables\u001b[39;00m\n\u001b[32m    208\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m info = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkafka_voters_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwrite_disposition\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mappend\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#merge_key=None,  # Set this to your primary key if you want upsert behavior\u001b[39;49;00m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#if_exists='append'  # 'append' will add to existing tables, 'replace' would drop and recreate\u001b[39;49;00m\n\u001b[32m    216\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mDLT installation test successful\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py:221\u001b[39m, in \u001b[36mwith_runtime_trace.<locals>.decorator.<locals>._wrap\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trace:\n\u001b[32m    219\u001b[39m         trace_step = start_trace_step(trace, cast(TPipelineStep, f.\u001b[34m__name__\u001b[39m), \u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     step_info = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m step_info\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py:270\u001b[39m, in \u001b[36mwith_config_section.<locals>.decorator.<locals>._wrap\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrap\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, *args: Any, **kwargs: Any) -> Any:\n\u001b[32m    264\u001b[39m     \u001b[38;5;66;03m# add section context to the container to be used by all configuration without explicit sections resolution\u001b[39;00m\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inject_section(\n\u001b[32m    266\u001b[39m         ConfigSectionContext(\n\u001b[32m    267\u001b[39m             pipeline_name=\u001b[38;5;28mself\u001b[39m.pipeline_name, sections=sections, merge_style=merge_func\n\u001b[32m    268\u001b[39m         )\n\u001b[32m    269\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py:730\u001b[39m, in \u001b[36mPipeline.run\u001b[39m\u001b[34m(self, data, destination, staging, dataset_name, credentials, table_name, write_disposition, columns, primary_key, schema, loader_file_format, table_format, schema_contract, refresh)\u001b[39m\n\u001b[32m    728\u001b[39m \u001b[38;5;66;03m# extract from the source\u001b[39;00m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m730\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwrite_disposition\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrite_disposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprimary_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprimary_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m        \u001b[49m\u001b[43mschema_contract\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema_contract\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    741\u001b[39m     \u001b[38;5;28mself\u001b[39m.normalize(loader_file_format=loader_file_format)\n\u001b[32m    742\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.load(destination, dataset_name, credentials=credentials)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py:221\u001b[39m, in \u001b[36mwith_runtime_trace.<locals>.decorator.<locals>._wrap\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trace:\n\u001b[32m    219\u001b[39m         trace_step = start_trace_step(trace, cast(TPipelineStep, f.\u001b[34m__name__\u001b[39m), \u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     step_info = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m step_info\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py:175\u001b[39m, in \u001b[36mwith_schemas_sync.<locals>._wrap\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m     \u001b[38;5;28mself\u001b[39m._schema_storage.commit_live_schema(name)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     rv = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    177\u001b[39m     \u001b[38;5;66;03m# because we committed live schema before calling f, we may safely\u001b[39;00m\n\u001b[32m    178\u001b[39m     \u001b[38;5;66;03m# drop all changes in live schemas\u001b[39;00m\n\u001b[32m    179\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m._schema_storage.live_schemas.keys()):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py:161\u001b[39m, in \u001b[36mwith_state_sync.<locals>.decorator.<locals>._wrap\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    159\u001b[39m should_extract_state = may_extract_state \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.restore_from_destination\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.managed_state(extract_state=should_extract_state):\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py:270\u001b[39m, in \u001b[36mwith_config_section.<locals>.decorator.<locals>._wrap\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrap\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, *args: Any, **kwargs: Any) -> Any:\n\u001b[32m    264\u001b[39m     \u001b[38;5;66;03m# add section context to the container to be used by all configuration without explicit sections resolution\u001b[39;00m\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inject_section(\n\u001b[32m    266\u001b[39m         ConfigSectionContext(\n\u001b[32m    267\u001b[39m             pipeline_name=\u001b[38;5;28mself\u001b[39m.pipeline_name, sections=sections, merge_style=merge_func\n\u001b[32m    268\u001b[39m         )\n\u001b[32m    269\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py:466\u001b[39m, in \u001b[36mPipeline.extract\u001b[39m\u001b[34m(self, data, table_name, parent_table_name, write_disposition, columns, primary_key, schema, max_parallel_items, workers, table_format, schema_contract, refresh)\u001b[39m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m source.exhausted:\n\u001b[32m    464\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SourceExhausted(source.name)\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extract_source\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextract_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_parallel_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;66;03m# this will update state version hash so it will not be extracted again by with_state_sync\u001b[39;00m\n\u001b[32m    475\u001b[39m \u001b[38;5;28mself\u001b[39m._bump_version_and_extract_state(\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m._container[StateInjectableContext].state,\n\u001b[32m    477\u001b[39m     \u001b[38;5;28mself\u001b[39m.config.restore_from_destination,\n\u001b[32m    478\u001b[39m     extract_step,\n\u001b[32m    479\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py:1238\u001b[39m, in \u001b[36mPipeline._extract_source\u001b[39m\u001b[34m(self, extract, source, max_parallel_items, workers, refresh, load_package_state_update)\u001b[39m\n\u001b[32m   1235\u001b[39m source.schema.update_normalizers()\n\u001b[32m   1237\u001b[39m \u001b[38;5;66;03m# extract into pipeline schema\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1238\u001b[39m load_id = \u001b[43mextract\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_parallel_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_package_state_update\u001b[49m\u001b[43m=\u001b[49m\u001b[43mload_package_state_update\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[38;5;66;03m# update live schema but not update the store yet\u001b[39;00m\n\u001b[32m   1243\u001b[39m source.schema = \u001b[38;5;28mself\u001b[39m._schema_storage.set_live_schema(source.schema)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/extract/extract.py:435\u001b[39m, in \u001b[36mExtract.extract\u001b[39m\u001b[34m(self, source, max_parallel_items, workers, load_package_state_update)\u001b[39m\n\u001b[32m    432\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m resource.write_disposition == \u001b[33m\"\u001b[39m\u001b[33mreplace\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    433\u001b[39m                     reset_resource_state(resource.name)\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extract_single_source\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m            \u001b[49m\u001b[43mload_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m            \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_parallel_items\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_parallel_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m         commit_load_package_state()\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m load_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/extract/extract.py:358\u001b[39m, in \u001b[36mExtract._extract_single_source\u001b[39m\u001b[34m(self, load_id, source, max_parallel_items, workers)\u001b[39m\n\u001b[32m    356\u001b[39m left_gens = total_gens = \u001b[38;5;28mlen\u001b[39m(pipes._sources)\n\u001b[32m    357\u001b[39m collector.update(\u001b[33m\"\u001b[39m\u001b[33mResources\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m, total_gens)\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpipe_item\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpipes\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcurr_gens\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpipes\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_sources\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mleft_gens\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr_gens\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/extract/pipe_iterator.py:162\u001b[39m, in \u001b[36mPipeIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    158\u001b[39m pipe_item = \u001b[38;5;28mself\u001b[39m._futures_pool.resolve_next_future_no_wait()\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pipe_item \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# if none then take element from the newest source\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     pipe_item = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_source_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pipe_item \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Wait for some time for futures to resolve\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/extract/pipe_iterator.py:277\u001b[39m, in \u001b[36mPipeIterator._get_source_item\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    274\u001b[39m gen, step, pipe, meta = \u001b[38;5;28mself\u001b[39m._sources[\u001b[38;5;28mself\u001b[39m._current_source_index]\n\u001b[32m    275\u001b[39m set_current_pipe_name(pipe.name)\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m pipe_item = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pipe_item \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    279\u001b[39m     \u001b[38;5;66;03m# full pipe item may be returned, this is used by ForkPipe step\u001b[39;00m\n\u001b[32m    280\u001b[39m     \u001b[38;5;66;03m# to redirect execution of an item to another pipe\u001b[39;00m\n\u001b[32m    281\u001b[39m     \u001b[38;5;66;03m# else\u001b[39;00m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pipe_item, ResolvablePipeItem):\n\u001b[32m    283\u001b[39m         \u001b[38;5;66;03m# keep the item assigned step and pipe when creating resolvable item\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mkafka_voters_source\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mkafka_voters_source\u001b[39m():\n\u001b[32m     58\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Source function that reads voters from Kafka\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     consumer = \u001b[43mKafkaConsumer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvoters\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbootstrap_servers\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlocalhost:29092\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m        \u001b[49m\u001b[43mauto_offset_reset\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mearliest\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue_deserializer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdlt-voter-group\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m consumer:\n\u001b[32m     68\u001b[39m         logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived voter message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage.value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/kafka/consumer/group.py:383\u001b[39m, in \u001b[36mKafkaConsumer.__init__\u001b[39m\u001b[34m(self, *topics, **configs)\u001b[39m\n\u001b[32m    379\u001b[39m         \u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mapi_version\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, str_version.split(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)))\n\u001b[32m    380\u001b[39m     log.warning(\u001b[33m'\u001b[39m\u001b[33muse api_version=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m [tuple] -- \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m as str is deprecated\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    381\u001b[39m                 \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mapi_version\u001b[39m\u001b[33m'\u001b[39m]), str_version)\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m \u001b[38;5;28mself\u001b[39m._client = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mkafka_client\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[38;5;66;03m# Get auto-discovered / normalized version from client\u001b[39;00m\n\u001b[32m    386\u001b[39m \u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mapi_version\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m._client.config[\u001b[33m'\u001b[39m\u001b[33mapi_version\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/kafka/client_async.py:262\u001b[39m, in \u001b[36mKafkaClient.__init__\u001b[39m\u001b[34m(self, **configs)\u001b[39m\n\u001b[32m    260\u001b[39m \u001b[38;5;66;03m# Check Broker Version if not set explicitly\u001b[39;00m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mapi_version\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mapi_version\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mapi_version\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m BROKER_API_VERSIONS:\n\u001b[32m    264\u001b[39m     \u001b[38;5;28mself\u001b[39m._api_versions = BROKER_API_VERSIONS[\u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mapi_version\u001b[39m\u001b[33m'\u001b[39m]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/kafka/client_async.py:1049\u001b[39m, in \u001b[36mKafkaClient.check_version\u001b[39m\u001b[34m(self, node_id, timeout, **kwargs)\u001b[39m\n\u001b[32m   1047\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sleep_time > \u001b[32m0\u001b[39m:\n\u001b[32m   1048\u001b[39m         log.warning(\u001b[33m'\u001b[39m\u001b[33mNo node available during check_version; sleeping \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[33m secs\u001b[39m\u001b[33m'\u001b[39m, sleep_time)\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msleep_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1050\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1051\u001b[39m log.debug(\u001b[33m'\u001b[39m\u001b[33mAttempting to check version with node \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m, try_node)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Debug script to test DLT pipeline components one by one\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "from kafka import KafkaConsumer\n",
    "from dlt.destinations import postgres\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger('debug')\n",
    "\n",
    "pipeline_name = 'voters'\n",
    "table_name = 'voters'\n",
    "\n",
    "def get_destination_config():\n",
    "    \"\"\"Get destination configuration based on storage preference\"\"\"\n",
    "    storage_preference = os.environ.get('STORAGE_PREFERENCE', 'postgres').upper()\n",
    "    \n",
    "    if storage_preference == 'GCP':\n",
    "        # Check if GCP credentials file path is provided\n",
    "        gcp_creds_path = os.environ.get('GCP_CREDENTIALS_PATH')\n",
    "        \n",
    "        if gcp_creds_path and os.path.exists(gcp_creds_path):\n",
    "            # Load GCP credentials from file\n",
    "            with open(gcp_creds_path, 'r') as f:\n",
    "                gcp_creds = json.load(f)\n",
    "            return 'bigquery', gcp_creds\n",
    "        else:\n",
    "            # If credentials file is not provided, try to use application default credentials\n",
    "            print(\"GCP credentials file not found, using application default credentials\")\n",
    "            return 'bigquery', None\n",
    "    else:\n",
    "        # PostgreSQL connection\n",
    "        pg_host = os.environ.get('POSTGRES_HOST', 'localhost')\n",
    "        pg_port = os.environ.get('POSTGRES_PORT', '5432')\n",
    "        pg_db = os.environ.get('POSTGRES_DB', 'voting_db')\n",
    "        pg_user = os.environ.get('POSTGRES_USER', 'postgres')\n",
    "        pg_password = os.environ.get('POSTGRES_PASSWORD', 'postgres')\n",
    "        \n",
    "        connection_string = f\"postgresql://{pg_user}:{pg_password}@{pg_host}:{pg_port}/{pg_db}\"\n",
    "        return 'postgres', connection_string\n",
    "\n",
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import dlt\n",
    "\n",
    "def kafka_voters_source():\n",
    "    \"\"\"Source function that reads voters from Kafka\"\"\"\n",
    "    consumer = KafkaConsumer(\n",
    "        'voters',\n",
    "        bootstrap_servers=['localhost:29092'],\n",
    "        auto_offset_reset='earliest',\n",
    "        value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n",
    "        group_id='dlt-voter-group'\n",
    "    )\n",
    "    \n",
    "    for message in consumer:\n",
    "        logger.info(f\"Received voter message: {message.value}\")\n",
    "        yield message.value\n",
    "\n",
    "def kafka_votes_source():\n",
    "    \"\"\"Source function that reads votes from Kafka\"\"\"\n",
    "    consumer = KafkaConsumer(\n",
    "        'votes',\n",
    "        bootstrap_servers=['localhost:29092'],\n",
    "        auto_offset_reset='earliest',\n",
    "        value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n",
    "        group_id='dlt-votes-group'\n",
    "    )\n",
    "    \n",
    "    for message in consumer:\n",
    "        yield message.value\n",
    "\n",
    "def test_kafka_connection():\n",
    "    \"\"\"Test connection to Kafka\"\"\"\n",
    "    bootstrap_servers = os.environ.get('KAFKA_BOOTSTRAP_SERVERS', 'localhost:29092')\n",
    "    logger.info(f\"Testing Kafka connection to {bootstrap_servers}\")\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"Creating test consumer...\")\n",
    "        consumer = KafkaConsumer(\n",
    "            bootstrap_servers=[bootstrap_servers],\n",
    "            group_id='debug-group',\n",
    "            auto_offset_reset='earliest',\n",
    "            consumer_timeout_ms=3000\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Listing topics...\")\n",
    "        topics = consumer.topics()\n",
    "        logger.info(f\"Available topics: {topics}\")\n",
    "        \n",
    "        consumer.close()\n",
    "        logger.info(\"Kafka connection test successful\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Kafka connection failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def test_voter_topic():\n",
    "    \"\"\"Test the voters topic in Kafka\"\"\"\n",
    "    bootstrap_servers = os.environ.get('KAFKA_BOOTSTRAP_SERVERS', 'localhost:29092')\n",
    "    logger.info(f\"Testing voter topic in Kafka at {bootstrap_servers}\")\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"Creating voter consumer...\")\n",
    "        consumer = KafkaConsumer(\n",
    "            'voters',\n",
    "            bootstrap_servers=[bootstrap_servers],\n",
    "            auto_offset_reset='earliest',\n",
    "            value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n",
    "            group_id='debug-voter-group',\n",
    "            consumer_timeout_ms=3000  # 30 seconds timeout\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Attempting to poll messages from voter topic...\")\n",
    "        messages = consumer.poll(timeout_ms=30000, max_records=10)\n",
    "        \n",
    "        if messages:\n",
    "            logger.info(f\"Found {len(messages)} message partitions\")\n",
    "            for tp, msgs in messages.items():\n",
    "                logger.info(f\"Topic-partition {tp} has {len(msgs)} messages\")\n",
    "                for msg in msgs[:3]:  # Show up to 3 messages\n",
    "                    logger.info(f\"Sample message: {msg.value}\")\n",
    "        else:\n",
    "            logger.warning(\"No messages found in voter topic\")\n",
    "        \n",
    "        consumer.close()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Voter topic test failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def test_postgres_connection():\n",
    "    \"\"\"Test connection to PostgreSQL\"\"\"\n",
    "    import psycopg2\n",
    "    \n",
    "    pg_host = os.environ.get('POSTGRES_HOST', 'localhost')\n",
    "    pg_port = os.environ.get('POSTGRES_PORT', '5432')\n",
    "    pg_db = os.environ.get('POSTGRES_DB', 'voting_db')\n",
    "    pg_user = os.environ.get('POSTGRES_USER', 'postgres')\n",
    "    pg_password = os.environ.get('POSTGRES_PASSWORD', 'postgres')\n",
    "    \n",
    "    logger.info(f\"Testing PostgreSQL connection to {pg_host}:{pg_port}/{pg_db}\")\n",
    "    \n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            host=pg_host,\n",
    "            port=pg_port,\n",
    "            dbname=pg_db,\n",
    "            user=pg_user,\n",
    "            password=pg_password\n",
    "        )\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT 1\")\n",
    "        result = cursor.fetchone()\n",
    "        \n",
    "        logger.info(f\"PostgreSQL connection test successful: {result}\")\n",
    "        \n",
    "        # Check if tables exist\n",
    "        cursor.execute(\"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'voters')\")\n",
    "        voters_table_exists = cursor.fetchone()[0]\n",
    "        \n",
    "        cursor.execute(\"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'votes')\")\n",
    "        votes_table_exists = cursor.fetchone()[0]\n",
    "        \n",
    "        logger.info(f\"Tables exist check - voters: {voters_table_exists}, votes: {votes_table_exists}\")\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"PostgreSQL connection failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def test_dlt_installation():\n",
    "    \"\"\"Test if DLT is installed and working\"\"\"\n",
    "    try:\n",
    "        import dlt\n",
    "        logger.info(f\"DLT version: {dlt.__version__}\")\n",
    "        \n",
    "        # Test basic pipeline creation\n",
    "        # pipeline = dlt.pipeline(\n",
    "        #     pipeline_name='debug_pipeline',\n",
    "        #     destination='dummy'\n",
    "        # )\n",
    "        # pipeline = dlt.pipeline(\n",
    "        #     pipeline_name=\"ny_taxi_pipeline\",\n",
    "        #     destination=\"duckdb\",\n",
    "        #     dataset_name=\"ny_taxi_data\"\n",
    "        # )\n",
    "        destination_type, destination_config = get_destination_config()\n",
    "        pipeline = dlt.pipeline(\n",
    "            pipeline_name=pipeline_name,\n",
    "            destination=postgres(destination_config),\n",
    "            dataset_name='public',  # Use 'public' schema or whatever schema your tables are in\n",
    "            dev_mode=True  # This forces DLT to recreate all internal state tables\n",
    "        )\n",
    "\n",
    "        info = pipeline.run(\n",
    "                kafka_voters_source,\n",
    "                table_name=table_name,\n",
    "                write_disposition='append',\n",
    "                #merge_key=None,  # Set this to your primary key if you want upsert behavior\n",
    "                #if_exists='append'  # 'append' will add to existing tables, 'replace' would drop and recreate\n",
    "            )\n",
    "        logger.info(\"DLT installation test successful\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"DLT installation test failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run all tests\"\"\"\n",
    "    logger.info(\"Starting debug tests...\")\n",
    "    \n",
    "    # Print environment variables\n",
    "    # logger.info(\"Environment variables:\")\n",
    "    # for key, value in os.environ.items():\n",
    "    #     if 'PASSWORD' not in key:  # Don't log passwords\n",
    "    #         logger.info(f\"{key}={value}\")\n",
    "    \n",
    "    # Test components\n",
    "    kafka_ok = test_kafka_connection()\n",
    "    voter_topic_ok = test_voter_topic() if kafka_ok else False\n",
    "    postgres_ok = test_postgres_connection()\n",
    "    dlt_ok = test_dlt_installation()\n",
    "    \n",
    "    logger.info(\"\\n----- TEST RESULTS -----\")\n",
    "    logger.info(f\"Kafka Connection: {'✅' if kafka_ok else '❌'}\")\n",
    "    logger.info(f\"Voter Topic: {'✅' if voter_topic_ok else '❌'}\")\n",
    "    logger.info(f\"PostgreSQL Connection: {'✅' if postgres_ok else '❌'}\")\n",
    "    logger.info(f\"DLT Installation: {'✅' if dlt_ok else '❌'}\")\n",
    "    \n",
    "    # Wait to keep the container running\n",
    "    logger.info(\"Debug tests completed. Container will remain running for 10 minutes.\")\n",
    "    for i in range(10):\n",
    "        time.sleep(60)\n",
    "        logger.info(f\"Debug container alive - {i+1}/10 minutes\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6280a952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f74514e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 22:06:56,566 - INFO - Starting debug tests...\n",
      "2025-04-13 22:06:56,567 - INFO - Testing Kafka connection to localhost:29092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 22:06:56,568 - INFO - Creating test consumer...\n",
      "2025-04-13 22:06:56,571 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 22:06:56,572 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:56,572 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:56,573 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: connecting to localhost:29092 [('127.0.0.1', 29092) IPv4]\n",
      "2025-04-13 22:06:56,574 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:56,574 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:56,575 - WARNING - No node available during check_version; sleeping 0.05 secs\n",
      "2025-04-13 22:06:56,631 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 22:06:56,632 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:56,632 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:56,633 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: connecting to localhost:29092 [('127.0.0.1', 29092) IPv4]\n",
      "2025-04-13 22:06:56,634 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:56,634 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:56,635 - WARNING - No node available during check_version; sleeping 0.09 secs\n",
      "2025-04-13 22:06:56,724 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 22:06:56,725 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:56,725 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:56,726 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: connecting to localhost:29092 [('127.0.0.1', 29092) IPv4]\n",
      "2025-04-13 22:06:56,727 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:56,728 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:56,728 - WARNING - No node available during check_version; sleeping 0.18 secs\n",
      "2025-04-13 22:06:56,908 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 22:06:56,909 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:56,910 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:56,910 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: connecting to localhost:29092 [('127.0.0.1', 29092) IPv4]\n",
      "2025-04-13 22:06:56,911 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:56,911 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:56,912 - WARNING - No node available during check_version; sleeping 0.46 secs\n",
      "2025-04-13 22:06:57,374 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 22:06:57,375 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:57,376 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:57,376 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: connecting to localhost:29092 [('127.0.0.1', 29092) IPv4]\n",
      "2025-04-13 22:06:57,377 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:57,377 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:57,378 - WARNING - No node available during check_version; sleeping 0.93 secs\n",
      "2025-04-13 22:06:58,308 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 22:06:58,308 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:58,309 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:58,310 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: connecting to localhost:29092 [('127.0.0.1', 29092) IPv4]\n",
      "2025-04-13 22:06:58,311 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Connect attempt returned error 111. Disconnecting.\n",
      "2025-04-13 22:06:58,311 - ERROR - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv4 ('127.0.0.1', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED\n",
      "2025-04-13 22:06:58,312 - WARNING - No node available during check_version; sleeping 0.26 secs\n",
      "2025-04-13 22:06:58,571 - ERROR - Kafka connection failed: NoBrokersAvailable\n",
      "2025-04-13 22:06:58,572 - ERROR - Traceback: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_65558/1082509342.py\", line 196, in test_kafka_connection\n",
      "    consumer = KafkaConsumer(\n",
      "               ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/kafka/consumer/group.py\", line 383, in __init__\n",
      "    self._client = self.config['kafka_client'](metrics=self._metrics, **self.config)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/kafka/client_async.py\", line 262, in __init__\n",
      "    self.config['api_version'] = self.check_version()\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/kafka/client_async.py\", line 1073, in check_version\n",
      "    raise Errors.NoBrokersAvailable()\n",
      "kafka.errors.NoBrokersAvailable: NoBrokersAvailable\n",
      "\n",
      "2025-04-13 22:06:58,573 - INFO - Testing PostgreSQL connection to localhost:5432/voting_db\n",
      "2025-04-13 22:06:58,573 - ERROR - PostgreSQL connection failed: connection to server at \"localhost\" (::1), port 5432 failed: Connection refused\n",
      "\tIs the server running on that host and accepting TCP/IP connections?\n",
      "connection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused\n",
      "\tIs the server running on that host and accepting TCP/IP connections?\n",
      "\n",
      "2025-04-13 22:06:58,574 - ERROR - Traceback: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_65558/1082509342.py\", line 264, in test_postgres_connection\n",
      "    conn = psycopg2.connect(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/psycopg2/__init__.py\", line 122, in connect\n",
      "    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "psycopg2.OperationalError: connection to server at \"localhost\" (::1), port 5432 failed: Connection refused\n",
      "\tIs the server running on that host and accepting TCP/IP connections?\n",
      "connection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused\n",
      "\tIs the server running on that host and accepting TCP/IP connections?\n",
      "\n",
      "\n",
      "2025-04-13 22:06:58,575 - INFO - \n",
      "----- TEST RESULTS -----\n",
      "2025-04-13 22:06:58,575 - INFO - Kafka Connection: ❌\n",
      "2025-04-13 22:06:58,576 - INFO - Voter Topic: ❌\n",
      "2025-04-13 22:06:58,577 - INFO - PostgreSQL Connection: ❌\n",
      "2025-04-13 22:06:58,577 - INFO - DLT Installation: ❌\n",
      "2025-04-13 22:06:58,578 - INFO - \n",
      "----- TROUBLESHOOTING RECOMMENDATIONS -----\n",
      "2025-04-13 22:06:58,578 - INFO - - Fix Kafka connection issues before proceeding\n",
      "2025-04-13 22:06:58,579 - INFO - Debug tests completed. Container will remain running for 10 minutes.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 454\u001b[39m\n\u001b[32m    451\u001b[39m         logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDebug container alive - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/10 minutes\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 450\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    448\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mDebug tests completed. Container will remain running for 10 minutes.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDebug container alive - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/10 minutes\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Debug script to test DLT pipeline components one by one\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "import traceback\n",
    "from kafka import KafkaConsumer\n",
    "from dlt.destinations import postgres\n",
    "from datetime import datetime\n",
    "from uuid import uuid4\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger('debug')\n",
    "\n",
    "pipeline_name = 'voters'\n",
    "table_name = 'voters'\n",
    "\n",
    "def test_source(limit=5):\n",
    "    for i in range(limit):\n",
    "        yield {\n",
    "            \"voter_id\": f\"voter_{i}\",\n",
    "            \"name\": f\"Test Voter {i}\",\n",
    "            \"age\": 25 + i,\n",
    "            \"gender\": \"female\" if i % 2 == 0 else \"male\",\n",
    "            \"state\": \"TestState\",\n",
    "            \"county\": \"TestCounty\",\n",
    "            \"registration_date\": datetime.utcnow().isoformat()\n",
    "        }\n",
    "\n",
    "def get_destination_config():\n",
    "    \"\"\"Get destination configuration based on storage preference\"\"\"\n",
    "    storage_preference = os.environ.get('STORAGE_PREFERENCE', 'postgres').upper()\n",
    "    \n",
    "    if storage_preference == 'GCP':\n",
    "        # Check if GCP credentials file path is provided\n",
    "        gcp_creds_path = os.environ.get('GCP_CREDENTIALS_PATH')\n",
    "        \n",
    "        if gcp_creds_path and os.path.exists(gcp_creds_path):\n",
    "            # Load GCP credentials from file\n",
    "            with open(gcp_creds_path, 'r') as f:\n",
    "                gcp_creds = json.load(f)\n",
    "            return 'bigquery', gcp_creds\n",
    "        else:\n",
    "            # If credentials file is not provided, try to use application default credentials\n",
    "            logger.info(\"GCP credentials file not found, using application default credentials\")\n",
    "            return 'bigquery', None\n",
    "    else:\n",
    "        # PostgreSQL connection\n",
    "        pg_host = os.environ.get('POSTGRES_HOST', 'localhost')\n",
    "        pg_port = os.environ.get('POSTGRES_PORT', '5432')\n",
    "        pg_db = os.environ.get('POSTGRES_DB', 'voting_db')\n",
    "        pg_user = os.environ.get('POSTGRES_USER', 'postgres')\n",
    "        pg_password = os.environ.get('POSTGRES_PASSWORD', 'postgres')\n",
    "        \n",
    "        connection_string = f\"postgresql://{pg_user}:{pg_password}@{pg_host}:{pg_port}/{pg_db}\"\n",
    "        return 'postgres', connection_string\n",
    "\n",
    "def kafka_voters_source(limit=None):\n",
    "    \"\"\"Source function that reads voters from Kafka\"\"\"\n",
    "    bootstrap_servers = os.environ.get('KAFKA_BOOTSTRAP_SERVERS', 'localhost:29092')\n",
    "    topic = os.environ.get('KAFKA_VOTERS_TOPIC', 'voters')\n",
    "    \n",
    "    logger.info(f\"Starting Kafka consumer for topic '{topic}' at {bootstrap_servers}\")\n",
    "    \n",
    "    consumer = KafkaConsumer(\n",
    "        topic,\n",
    "        bootstrap_servers=[bootstrap_servers],\n",
    "        auto_offset_reset='earliest',\n",
    "        value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n",
    "        group_id=f'dlt-voter-group-{uuid4()}', #'dlt-voter-group' #,\n",
    "        #consumer_timeout_ms=3000  # 30 seconds timeout\n",
    "    )\n",
    "    \n",
    "    count = 0\n",
    "    for message in consumer:\n",
    "        voter_data = message.value\n",
    "        logger.info(f\"Processing voter record: {voter_data}\")\n",
    "        yield voter_data\n",
    "        \n",
    "        count += 1\n",
    "        if limit is not None and count >= limit:\n",
    "            logger.info(f\"Reached limit of {limit} records, stopping\")\n",
    "            break\n",
    "    \n",
    "    logger.info(\"Finished reading from Kafka, closing consumer\")\n",
    "    consumer.close()\n",
    "\n",
    "def kafka_voters_source2(limit=None):\n",
    "    \"\"\"Source function that reads voters from Kafka\"\"\"\n",
    "    bootstrap_servers = os.environ.get('KAFKA_BOOTSTRAP_SERVERS', 'localhost:29092')\n",
    "    topic = os.environ.get('KAFKA_VOTERS_TOPIC', 'voters')\n",
    "    \n",
    "    logger.info(f\"Starting Kafka consumer for topic '{topic}' at {bootstrap_servers}\")\n",
    "    \n",
    "    consumer = KafkaConsumer(\n",
    "        topic,\n",
    "        bootstrap_servers=[bootstrap_servers],\n",
    "        auto_offset_reset='earliest',\n",
    "        value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n",
    "        group_id=f'dlt-voter-group-test',\n",
    "        consumer_timeout_ms=5000\n",
    "    )\n",
    "\n",
    "    logger.info(\"Polling messages (test mode)...\")\n",
    "    polled = consumer.poll(timeout_ms=5000, max_records=limit or 10)\n",
    "    \n",
    "    if polled:\n",
    "        for tp, msgs in polled.items():\n",
    "            for msg in msgs:\n",
    "                logger.info(f\"Polled voter record: {msg.value}\")\n",
    "                yield msg.value\n",
    "    else:\n",
    "        logger.warning(\"No messages were polled from Kafka.\")\n",
    "    \n",
    "    consumer.close()\n",
    "\n",
    "def kafka_voters_source3(limit=None):\n",
    "    bootstrap_servers = os.environ.get('KAFKA_BOOTSTRAP_SERVERS', 'localhost:29092')\n",
    "    topic = os.environ.get('KAFKA_VOTERS_TOPIC', 'voters')\n",
    "    logger.info(f\"Starting Kafka consumer for topic '{topic}' at {bootstrap_servers}\")\n",
    "    \n",
    "    consumer = KafkaConsumer(\n",
    "        topic,\n",
    "        bootstrap_servers=[bootstrap_servers],\n",
    "        auto_offset_reset='earliest',\n",
    "        value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n",
    "        group_id='dlt-voter-group',\n",
    "        #consumer_timeout_ms=10000\n",
    "        enable_auto_commit=True\n",
    "    )\n",
    "\n",
    "    count = 0\n",
    "    while True:\n",
    "        messages = consumer.poll(timeout_ms=10000, max_records=10)\n",
    "        if not messages:\n",
    "            break  # end iteration if nothing found (for one-off runs)\n",
    "\n",
    "        for tp, msgs in messages.items():\n",
    "            for message in msgs:\n",
    "                yield message.value\n",
    "                count += 1\n",
    "                if limit is not None and count >= limit:\n",
    "                    consumer.close()\n",
    "                    return\n",
    "\n",
    "    logger.info(\"Finished reading from Kafka, closing consumer\")\n",
    "    consumer.close()\n",
    "\n",
    "\n",
    "\n",
    "def kafka_votes_source(limit=None):\n",
    "    \"\"\"Source function that reads votes from Kafka\"\"\"\n",
    "    bootstrap_servers = os.environ.get('KAFKA_BOOTSTRAP_SERVERS', 'localhost:29092')\n",
    "    topic = os.environ.get('KAFKA_VOTES_TOPIC', 'votes')\n",
    "    \n",
    "    logger.info(f\"Starting Kafka consumer for topic '{topic}' at {bootstrap_servers}\")\n",
    "    \n",
    "    consumer = KafkaConsumer(\n",
    "        topic,\n",
    "        bootstrap_servers=[bootstrap_servers],\n",
    "        auto_offset_reset='earliest',\n",
    "        value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n",
    "        group_id= f'dlt-voter-group-{uuid4()}', #'dlt-votes-group',\n",
    "        consumer_timeout_ms=30000  # 30 seconds timeout\n",
    "    )\n",
    "    \n",
    "    count = 0\n",
    "    for message in consumer:\n",
    "        vote_data = message.value\n",
    "        logger.info(f\"Processing vote record: {vote_data}\")\n",
    "        yield vote_data\n",
    "        \n",
    "        count += 1\n",
    "        if limit is not None and count >= limit:\n",
    "            logger.info(f\"Reached limit of {limit} records, stopping\")\n",
    "            break\n",
    "    \n",
    "    logger.info(\"Finished reading from Kafka, closing consumer\")\n",
    "    consumer.close()\n",
    "\n",
    "def test_kafka_connection():\n",
    "    \"\"\"Test connection to Kafka\"\"\"\n",
    "    bootstrap_servers = os.environ.get('KAFKA_BOOTSTRAP_SERVERS', 'localhost:29092')\n",
    "    logger.info(f\"Testing Kafka connection to {bootstrap_servers}\")\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"Creating test consumer...\")\n",
    "        consumer = KafkaConsumer(\n",
    "            bootstrap_servers=[bootstrap_servers],\n",
    "            group_id='debug-group',\n",
    "            auto_offset_reset='earliest',\n",
    "            consumer_timeout_ms=3000\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Listing topics...\")\n",
    "        topics = consumer.topics()\n",
    "        logger.info(f\"Available topics: {topics}\")\n",
    "        \n",
    "        consumer.close()\n",
    "        logger.info(\"Kafka connection test successful\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Kafka connection failed: {str(e)}\")\n",
    "        logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "        return False\n",
    "\n",
    "def test_voter_topic():\n",
    "    \"\"\"Test the voters topic in Kafka\"\"\"\n",
    "    bootstrap_servers = os.environ.get('KAFKA_BOOTSTRAP_SERVERS', 'localhost:29092')\n",
    "    topic = os.environ.get('KAFKA_VOTERS_TOPIC', 'voters')\n",
    "    logger.info(f\"Testing '{topic}' topic in Kafka at {bootstrap_servers}\")\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"Creating consumer for topic '{topic}'...\")\n",
    "        consumer = KafkaConsumer(\n",
    "            topic,\n",
    "            bootstrap_servers=[bootstrap_servers],\n",
    "            auto_offset_reset='earliest',\n",
    "            value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n",
    "            group_id='debug-voter-group',\n",
    "            consumer_timeout_ms=10000  # 10 seconds timeout\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Attempting to poll messages from '{topic}' topic...\")\n",
    "        messages = consumer.poll(timeout_ms=10000, max_records=10)\n",
    "        \n",
    "        if messages:\n",
    "            logger.info(f\"Found {len(messages)} message partitions\")\n",
    "            for tp, msgs in messages.items():\n",
    "                logger.info(f\"Topic-partition {tp} has {len(msgs)} messages\")\n",
    "                for msg in msgs[:3]:  # Show up to 3 messages\n",
    "                    logger.info(f\"Sample message: {msg.value}\")\n",
    "        else:\n",
    "            logger.warning(f\"No messages found in '{topic}' topic\")\n",
    "        \n",
    "        consumer.close()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Topic '{topic}' test failed: {str(e)}\")\n",
    "        logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "        return False\n",
    "\n",
    "def test_postgres_connection():\n",
    "    \"\"\"Test connection to PostgreSQL\"\"\"\n",
    "    import psycopg2\n",
    "    \n",
    "    pg_host = os.environ.get('POSTGRES_HOST', 'localhost')\n",
    "    pg_port = os.environ.get('POSTGRES_PORT', '5432')\n",
    "    pg_db = os.environ.get('POSTGRES_DB', 'voting_db')\n",
    "    pg_user = os.environ.get('POSTGRES_USER', 'postgres')\n",
    "    pg_password = os.environ.get('POSTGRES_PASSWORD', 'postgres')\n",
    "    \n",
    "    logger.info(f\"Testing PostgreSQL connection to {pg_host}:{pg_port}/{pg_db}\")\n",
    "    \n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            host=pg_host,\n",
    "            port=pg_port,\n",
    "            dbname=pg_db,\n",
    "            user=pg_user,\n",
    "            password=pg_password\n",
    "        )\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT 1\")\n",
    "        result = cursor.fetchone()\n",
    "        \n",
    "        logger.info(f\"PostgreSQL connection test successful: {result}\")\n",
    "        \n",
    "        # Check if tables exist\n",
    "        cursor.execute(\"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'voters')\")\n",
    "        voters_table_exists = cursor.fetchone()[0]\n",
    "        \n",
    "        cursor.execute(\"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'votes')\")\n",
    "        votes_table_exists = cursor.fetchone()[0]\n",
    "        \n",
    "        logger.info(f\"Tables exist check - voters: {voters_table_exists}, votes: {votes_table_exists}\")\n",
    "        \n",
    "        # If voters table exists, inspect its schema\n",
    "        if voters_table_exists:\n",
    "            inspect_postgres_table(conn, 'voters')\n",
    "        \n",
    "        # If votes table exists, inspect its schema\n",
    "        if votes_table_exists:\n",
    "            inspect_postgres_table(conn, 'votes')\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"PostgreSQL connection failed: {str(e)}\")\n",
    "        logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "        return False\n",
    "\n",
    "def inspect_postgres_table(conn, table_name):\n",
    "    \"\"\"Inspect the structure of a table in PostgreSQL\"\"\"\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(f\"\"\"\n",
    "            SELECT column_name, data_type \n",
    "            FROM information_schema.columns \n",
    "            WHERE table_name = '{table_name}'\n",
    "            ORDER BY ordinal_position\n",
    "        \"\"\")\n",
    "        columns = cursor.fetchall()\n",
    "        \n",
    "        logger.info(f\"PostgreSQL '{table_name}' table schema:\")\n",
    "        for column in columns:\n",
    "            logger.info(f\"Column: {column[0]}, Type: {column[1]}\")\n",
    "            \n",
    "        # Get row count\n",
    "        cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n",
    "        row_count = cursor.fetchone()[0]\n",
    "        logger.info(f\"Table '{table_name}' has {row_count} rows\")\n",
    "        \n",
    "        # Get sample data if table has rows\n",
    "        if row_count > 0:\n",
    "            cursor.execute(f\"SELECT * FROM {table_name} LIMIT 3\")\n",
    "            sample_rows = cursor.fetchall()\n",
    "            logger.info(f\"Sample data from '{table_name}':\")\n",
    "            for i, row in enumerate(sample_rows):\n",
    "                logger.info(f\"Row {i+1}: {row}\")\n",
    "        \n",
    "        cursor.close()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error inspecting PostgreSQL table '{table_name}': {str(e)}\")\n",
    "        logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "\n",
    "def test_dlt_installation():\n",
    "    \"\"\"Test if DLT is installed and working\"\"\"\n",
    "    try:\n",
    "        import dlt\n",
    "        logger.info(f\"DLT version: {dlt.__version__}\")\n",
    "        \n",
    "        # Test basic pipeline creation\n",
    "        destination_type, destination_config = get_destination_config()\n",
    "        logger.info(f\"Creating DLT pipeline with destination type: {destination_type}\")\n",
    "        \n",
    "        try:\n",
    "            # Initialize pipeline\n",
    "            pipeline = dlt.pipeline(\n",
    "                pipeline_name=pipeline_name,\n",
    "                destination=postgres(destination_config),\n",
    "                dataset_name='public',  # Use 'public' schema or whatever schema your tables are in\n",
    "               # dev_mode=True  # This forces DLT to recreate all internal state tables\n",
    "            )\n",
    "            logger.info(\"Pipeline initialized successfully\")\n",
    "            \n",
    "            # Load a limited number of records for testing\n",
    "            logger.info(\"Running pipeline with limited data (5 records max)\")\n",
    "            try:\n",
    "                # logger.info(f\"test if we have data\")\n",
    "                # for msg in kafka_voters_source(3):\n",
    "                #     logger.info(f\"Sample Kafka record to dlt: {msg}\")\n",
    "                #     break\n",
    "\n",
    "                info = pipeline.run(\n",
    "                    kafka_voters_source(limit=1000),\n",
    "                    #kafka_voters_source3(limit=None),\n",
    "                    #test_source(limit=5),\n",
    "                    table_name='voters',\n",
    "                    write_disposition='append'\n",
    "                )\n",
    "                logger.info(f\"Pipeline run completed successfully. Load info: {info}\")\n",
    "                #logger.info(f\"Loaded {info.load_packages.normalized_rows_count} rows\")\n",
    "                \n",
    "                # Check table after loading\n",
    "                if destination_type == 'postgres':\n",
    "                    import psycopg2\n",
    "                    pg_host = os.environ.get('POSTGRES_HOST', 'localhost')\n",
    "                    pg_port = os.environ.get('POSTGRES_PORT', '5432')\n",
    "                    pg_db = os.environ.get('POSTGRES_DB', 'voting_db')\n",
    "                    pg_user = os.environ.get('POSTGRES_USER', 'postgres')\n",
    "                    pg_password = os.environ.get('POSTGRES_PASSWORD', 'postgres')\n",
    "                    \n",
    "                    try:\n",
    "                        conn = psycopg2.connect(\n",
    "                            host=pg_host,\n",
    "                            port=pg_port,\n",
    "                            dbname=pg_db,\n",
    "                            user=pg_user,\n",
    "                            password=pg_password\n",
    "                        )\n",
    "                        logger.info(\"Checking table after DLT load\")\n",
    "                        inspect_postgres_table(conn, table_name)\n",
    "                        conn.close()\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Failed to check table after load: {str(e)}\")\n",
    "                \n",
    "                return True\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Pipeline run failed: {str(e)}\")\n",
    "                logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Pipeline creation failed: {str(e)}\")\n",
    "            logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        logger.error(f\"DLT installation test failed: {str(e)}\")\n",
    "        logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run all tests\"\"\"\n",
    "    logger.info(\"Starting debug tests...\")\n",
    "    \n",
    "    # Print environment variables\n",
    "    # logger.info(\"Environment variables:\")\n",
    "    # for key, value in os.environ.items():\n",
    "    #     if 'PASSWORD' not in key.upper():  # Don't log passwords\n",
    "    #         logger.info(f\"{key}={value}\")\n",
    "    \n",
    "    # Test components\n",
    "    kafka_ok = test_kafka_connection()\n",
    "    voter_topic_ok = test_voter_topic() if kafka_ok else False\n",
    "    postgres_ok = test_postgres_connection()\n",
    "    dlt_ok = test_dlt_installation() if kafka_ok and postgres_ok else False\n",
    "    \n",
    "    logger.info(\"\\n----- TEST RESULTS -----\")\n",
    "    logger.info(f\"Kafka Connection: {'✅' if kafka_ok else '❌'}\")\n",
    "    logger.info(f\"Voter Topic: {'✅' if voter_topic_ok else '❌'}\")\n",
    "    logger.info(f\"PostgreSQL Connection: {'✅' if postgres_ok else '❌'}\")\n",
    "    logger.info(f\"DLT Installation: {'✅' if dlt_ok else '❌'}\")\n",
    "    \n",
    "    if not dlt_ok:\n",
    "        logger.info(\"\\n----- TROUBLESHOOTING RECOMMENDATIONS -----\")\n",
    "        if not kafka_ok:\n",
    "            logger.info(\"- Fix Kafka connection issues before proceeding\")\n",
    "        elif not voter_topic_ok:\n",
    "            logger.info(\"- Ensure the 'voters' topic exists and has data\")\n",
    "        elif not postgres_ok:\n",
    "            logger.info(\"- Fix PostgreSQL connection issues before proceeding\")\n",
    "        else:\n",
    "            logger.info(\"- Check DLT pipeline configuration\")\n",
    "            logger.info(\"- Verify data format compatibility between Kafka and PostgreSQL\")\n",
    "            logger.info(\"- Examine error logs for specific DLT errors\")\n",
    "    \n",
    "    # Wait to keep the container running\n",
    "    logger.info(\"Debug tests completed. Container will remain running for 10 minutes.\")\n",
    "    for i in range(10):\n",
    "        time.sleep(60)\n",
    "        logger.info(f\"Debug container alive - {i+1}/10 minutes\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63be3fe0",
   "metadata": {},
   "source": [
    "### Final code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f27ad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Debug script to test DLT pipeline components one by one\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "import traceback\n",
    "from kafka import KafkaConsumer\n",
    "from dlt.destinations import postgres\n",
    "from datetime import datetime\n",
    "from uuid import uuid4\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger('debug')\n",
    "\n",
    "pipeline_name = 'voters'\n",
    "table_name = 'voters'\n",
    "\n",
    "def get_destination_config():\n",
    "    \"\"\"Get destination configuration based on storage preference\"\"\"\n",
    "    storage_preference = os.environ.get('STORAGE_PREFERENCE', 'postgres').upper()\n",
    "    \n",
    "    if storage_preference == 'GCP':\n",
    "        # Check if GCP credentials file path is provided\n",
    "        gcp_creds_path = os.environ.get('GCP_CREDENTIALS_PATH')\n",
    "        \n",
    "        if gcp_creds_path and os.path.exists(gcp_creds_path):\n",
    "            # Load GCP credentials from file\n",
    "            with open(gcp_creds_path, 'r') as f:\n",
    "                gcp_creds = json.load(f)\n",
    "            return 'bigquery', gcp_creds\n",
    "        else:\n",
    "            # If credentials file is not provided, try to use application default credentials\n",
    "            logger.info(\"GCP credentials file not found, using application default credentials\")\n",
    "            return 'bigquery', None\n",
    "    else:\n",
    "        # PostgreSQL connection\n",
    "        pg_host = os.environ.get('POSTGRES_HOST', 'localhost')\n",
    "        pg_port = os.environ.get('POSTGRES_PORT', '5432')\n",
    "        pg_db = os.environ.get('POSTGRES_DB', 'voting_db')\n",
    "        pg_user = os.environ.get('POSTGRES_USER', 'postgres')\n",
    "        pg_password = os.environ.get('POSTGRES_PASSWORD', 'postgres')\n",
    "        \n",
    "        connection_string = f\"postgresql://{pg_user}:{pg_password}@{pg_host}:{pg_port}/{pg_db}\"\n",
    "        return 'postgres', connection_string\n",
    "\n",
    "def kafka_voters_source(limit=None):\n",
    "    \"\"\"Source function that reads voters from Kafka\"\"\"\n",
    "    bootstrap_servers = os.environ.get('KAFKA_BOOTSTRAP_SERVERS', 'localhost:29092')\n",
    "    topic = os.environ.get('KAFKA_VOTERS_TOPIC', 'voters')\n",
    "    \n",
    "    logger.info(f\"Starting Kafka consumer for topic '{topic}' at {bootstrap_servers}\")\n",
    "    \n",
    "    consumer = KafkaConsumer(\n",
    "        topic,\n",
    "        bootstrap_servers=[bootstrap_servers],\n",
    "        auto_offset_reset='earliest',\n",
    "        value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n",
    "        group_id=f'dlt-voter-group-{uuid4()}', #'dlt-voter-group' #,\n",
    "        consumer_timeout_ms=3000  # 30 seconds timeout\n",
    "    )\n",
    "    \n",
    "    count = 0\n",
    "    for message in consumer:\n",
    "        voter_data = message.value\n",
    "        logger.info(f\"Processing voter record: {voter_data}\")\n",
    "        yield voter_data\n",
    "        \n",
    "        count += 1\n",
    "        if limit is not None and count >= limit:\n",
    "            logger.info(f\"Reached limit of {limit} records, stopping\")\n",
    "            break\n",
    "    \n",
    "    logger.info(\"Finished reading from Kafka, closing consumer\")\n",
    "    consumer.close()\n",
    "\n",
    "def kafka_votes_source(limit=None):\n",
    "    \"\"\"Source function that reads votes from Kafka\"\"\"\n",
    "    bootstrap_servers = os.environ.get('KAFKA_BOOTSTRAP_SERVERS', 'localhost:29092')\n",
    "    topic = os.environ.get('KAFKA_VOTES_TOPIC', 'votes')\n",
    "    \n",
    "    logger.info(f\"Starting Kafka consumer for topic '{topic}' at {bootstrap_servers}\")\n",
    "    \n",
    "    consumer = KafkaConsumer(\n",
    "        topic,\n",
    "        bootstrap_servers=[bootstrap_servers],\n",
    "        auto_offset_reset='earliest',\n",
    "        value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n",
    "        group_id= f'dlt-voter-group-{uuid4()}', #'dlt-votes-group',\n",
    "        consumer_timeout_ms=30000  # 30 seconds timeout\n",
    "    )\n",
    "    \n",
    "    count = 0\n",
    "    for message in consumer:\n",
    "        vote_data = message.value\n",
    "        logger.info(f\"Processing vote record: {vote_data}\")\n",
    "        yield vote_data\n",
    "        \n",
    "        count += 1\n",
    "        if limit is not None and count >= limit:\n",
    "            logger.info(f\"Reached limit of {limit} records, stopping\")\n",
    "            break\n",
    "    \n",
    "    logger.info(\"Finished reading from Kafka, closing consumer\")\n",
    "    consumer.close()\n",
    "\n",
    "def test_kafka_connection():\n",
    "    \"\"\"Test connection to Kafka\"\"\"\n",
    "    bootstrap_servers = os.environ.get('KAFKA_BOOTSTRAP_SERVERS', 'localhost:29092')\n",
    "    logger.info(f\"Testing Kafka connection to {bootstrap_servers}\")\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"Creating test consumer...\")\n",
    "        consumer = KafkaConsumer(\n",
    "            bootstrap_servers=[bootstrap_servers],\n",
    "            group_id='debug-group',\n",
    "            auto_offset_reset='earliest',\n",
    "            consumer_timeout_ms=3000\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Listing topics...\")\n",
    "        topics = consumer.topics()\n",
    "        logger.info(f\"Available topics: {topics}\")\n",
    "        \n",
    "        consumer.close()\n",
    "        logger.info(\"Kafka connection test successful\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Kafka connection failed: {str(e)}\")\n",
    "        logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "        return False\n",
    "\n",
    "def test_voter_topic():\n",
    "    \"\"\"Test the voters topic in Kafka\"\"\"\n",
    "    bootstrap_servers = os.environ.get('KAFKA_BOOTSTRAP_SERVERS', 'localhost:29092')\n",
    "    topic = os.environ.get('KAFKA_VOTERS_TOPIC', 'voters')\n",
    "    logger.info(f\"Testing '{topic}' topic in Kafka at {bootstrap_servers}\")\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"Creating consumer for topic '{topic}'...\")\n",
    "        consumer = KafkaConsumer(\n",
    "            topic,\n",
    "            bootstrap_servers=[bootstrap_servers],\n",
    "            auto_offset_reset='earliest',\n",
    "            value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n",
    "            group_id='debug-voter-group',\n",
    "            consumer_timeout_ms=10000  # 10 seconds timeout\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Attempting to poll messages from '{topic}' topic...\")\n",
    "        messages = consumer.poll(timeout_ms=10000, max_records=10)\n",
    "        \n",
    "        if messages:\n",
    "            logger.info(f\"Found {len(messages)} message partitions\")\n",
    "            for tp, msgs in messages.items():\n",
    "                logger.info(f\"Topic-partition {tp} has {len(msgs)} messages\")\n",
    "                for msg in msgs[:3]:  # Show up to 3 messages\n",
    "                    logger.info(f\"Sample message: {msg.value}\")\n",
    "        else:\n",
    "            logger.warning(f\"No messages found in '{topic}' topic\")\n",
    "        \n",
    "        consumer.close()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Topic '{topic}' test failed: {str(e)}\")\n",
    "        logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "        return False\n",
    "\n",
    "def test_postgres_connection():\n",
    "    \"\"\"Test connection to PostgreSQL\"\"\"\n",
    "    import psycopg2\n",
    "    \n",
    "    pg_host = os.environ.get('POSTGRES_HOST', 'localhost')\n",
    "    pg_port = os.environ.get('POSTGRES_PORT', '5432')\n",
    "    pg_db = os.environ.get('POSTGRES_DB', 'voting_db')\n",
    "    pg_user = os.environ.get('POSTGRES_USER', 'postgres')\n",
    "    pg_password = os.environ.get('POSTGRES_PASSWORD', 'postgres')\n",
    "    \n",
    "    logger.info(f\"Testing PostgreSQL connection to {pg_host}:{pg_port}/{pg_db}\")\n",
    "    \n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            host=pg_host,\n",
    "            port=pg_port,\n",
    "            dbname=pg_db,\n",
    "            user=pg_user,\n",
    "            password=pg_password\n",
    "        )\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT 1\")\n",
    "        result = cursor.fetchone()\n",
    "        \n",
    "        logger.info(f\"PostgreSQL connection test successful: {result}\")\n",
    "        \n",
    "        # Check if tables exist\n",
    "        cursor.execute(\"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'voters')\")\n",
    "        voters_table_exists = cursor.fetchone()[0]\n",
    "        \n",
    "        cursor.execute(\"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'votes')\")\n",
    "        votes_table_exists = cursor.fetchone()[0]\n",
    "        \n",
    "        logger.info(f\"Tables exist check - voters: {voters_table_exists}, votes: {votes_table_exists}\")\n",
    "        \n",
    "        # If voters table exists, inspect its schema\n",
    "        if voters_table_exists:\n",
    "            inspect_postgres_table(conn, 'voters')\n",
    "        \n",
    "        # If votes table exists, inspect its schema\n",
    "        if votes_table_exists:\n",
    "            inspect_postgres_table(conn, 'votes')\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"PostgreSQL connection failed: {str(e)}\")\n",
    "        logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "        return False\n",
    "\n",
    "def inspect_postgres_table(conn, table_name):\n",
    "    \"\"\"Inspect the structure of a table in PostgreSQL\"\"\"\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(f\"\"\"\n",
    "            SELECT column_name, data_type \n",
    "            FROM information_schema.columns \n",
    "            WHERE table_name = '{table_name}'\n",
    "            ORDER BY ordinal_position\n",
    "        \"\"\")\n",
    "        columns = cursor.fetchall()\n",
    "        \n",
    "        logger.info(f\"PostgreSQL '{table_name}' table schema:\")\n",
    "        for column in columns:\n",
    "            logger.info(f\"Column: {column[0]}, Type: {column[1]}\")\n",
    "            \n",
    "        # Get row count\n",
    "        cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n",
    "        row_count = cursor.fetchone()[0]\n",
    "        logger.info(f\"Table '{table_name}' has {row_count} rows\")\n",
    "        \n",
    "        # Get sample data if table has rows\n",
    "        if row_count > 0:\n",
    "            cursor.execute(f\"SELECT * FROM {table_name} LIMIT 3\")\n",
    "            sample_rows = cursor.fetchall()\n",
    "            logger.info(f\"Sample data from '{table_name}':\")\n",
    "            for i, row in enumerate(sample_rows):\n",
    "                logger.info(f\"Row {i+1}: {row}\")\n",
    "        \n",
    "        cursor.close()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error inspecting PostgreSQL table '{table_name}': {str(e)}\")\n",
    "        logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "\n",
    "def test_dlt_installation():\n",
    "    \"\"\"Test if DLT is installed and working\"\"\"\n",
    "    try:\n",
    "        import dlt\n",
    "        logger.info(f\"DLT version: {dlt.__version__}\")\n",
    "        \n",
    "        # Test basic pipeline creation\n",
    "        destination_type, destination_config = get_destination_config()\n",
    "        logger.info(f\"Creating DLT pipeline with destination type: {destination_type}\")\n",
    "        \n",
    "        try:\n",
    "            # Initialize pipeline\n",
    "            pipeline = dlt.pipeline(\n",
    "                pipeline_name=pipeline_name,\n",
    "                destination=postgres(destination_config),\n",
    "                dataset_name='public',  # Use 'public' schema or whatever schema your tables are in\n",
    "               # dev_mode=True  # This forces DLT to recreate all internal state tables\n",
    "            )\n",
    "            logger.info(\"Pipeline initialized successfully\")\n",
    "            \n",
    "            # Load a limited number of records for testing\n",
    "            logger.info(\"Running pipeline with limited data (5 records max)\")\n",
    "            try:\n",
    "                info = pipeline.run(\n",
    "                    kafka_voters_source(limit=1000),\n",
    "                    table_name='voters',\n",
    "                    write_disposition='append'\n",
    "                )\n",
    "                logger.info(f\"Pipeline run completed successfully. Load info: {info}\")\n",
    "                #logger.info(f\"Loaded {info.load_packages.normalized_rows_count} rows\")\n",
    "                \n",
    "                # Check table after loading\n",
    "                if destination_type == 'postgres':\n",
    "                    import psycopg2\n",
    "                    pg_host = os.environ.get('POSTGRES_HOST', 'localhost')\n",
    "                    pg_port = os.environ.get('POSTGRES_PORT', '5432')\n",
    "                    pg_db = os.environ.get('POSTGRES_DB', 'voting_db')\n",
    "                    pg_user = os.environ.get('POSTGRES_USER', 'postgres')\n",
    "                    pg_password = os.environ.get('POSTGRES_PASSWORD', 'postgres')\n",
    "                    \n",
    "                    try:\n",
    "                        conn = psycopg2.connect(\n",
    "                            host=pg_host,\n",
    "                            port=pg_port,\n",
    "                            dbname=pg_db,\n",
    "                            user=pg_user,\n",
    "                            password=pg_password\n",
    "                        )\n",
    "                        logger.info(\"Checking table after DLT load\")\n",
    "                        inspect_postgres_table(conn, table_name)\n",
    "                        conn.close()\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Failed to check table after load: {str(e)}\")\n",
    "                \n",
    "                return True\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Pipeline run failed: {str(e)}\")\n",
    "                logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Pipeline creation failed: {str(e)}\")\n",
    "            logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        logger.error(f\"DLT installation test failed: {str(e)}\")\n",
    "        logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run all tests\"\"\"\n",
    "    logger.info(\"Starting debug tests...\")\n",
    "    \n",
    "    # Print environment variables\n",
    "    # logger.info(\"Environment variables:\")\n",
    "    # for key, value in os.environ.items():\n",
    "    #     if 'PASSWORD' not in key.upper():  # Don't log passwords\n",
    "    #         logger.info(f\"{key}={value}\")\n",
    "    \n",
    "    # Test components\n",
    "    kafka_ok = test_kafka_connection()\n",
    "    voter_topic_ok = test_voter_topic() if kafka_ok else False\n",
    "    postgres_ok = test_postgres_connection()\n",
    "    dlt_ok = test_dlt_installation() if kafka_ok and postgres_ok else False\n",
    "    \n",
    "    logger.info(\"\\n----- TEST RESULTS -----\")\n",
    "    logger.info(f\"Kafka Connection: {'✅' if kafka_ok else '❌'}\")\n",
    "    logger.info(f\"Voter Topic: {'✅' if voter_topic_ok else '❌'}\")\n",
    "    logger.info(f\"PostgreSQL Connection: {'✅' if postgres_ok else '❌'}\")\n",
    "    logger.info(f\"DLT Installation: {'✅' if dlt_ok else '❌'}\")\n",
    "    \n",
    "    if not dlt_ok:\n",
    "        logger.info(\"\\n----- TROUBLESHOOTING RECOMMENDATIONS -----\")\n",
    "        if not kafka_ok:\n",
    "            logger.info(\"- Fix Kafka connection issues before proceeding\")\n",
    "        elif not voter_topic_ok:\n",
    "            logger.info(\"- Ensure the 'voters' topic exists and has data\")\n",
    "        elif not postgres_ok:\n",
    "            logger.info(\"- Fix PostgreSQL connection issues before proceeding\")\n",
    "        else:\n",
    "            logger.info(\"- Check DLT pipeline configuration\")\n",
    "            logger.info(\"- Verify data format compatibility between Kafka and PostgreSQL\")\n",
    "            logger.info(\"- Examine error logs for specific DLT errors\")\n",
    "    \n",
    "    # Wait to keep the container running\n",
    "    logger.info(\"Debug tests completed. Container will remain running for 10 minutes.\")\n",
    "    for i in range(10):\n",
    "        time.sleep(60)\n",
    "        logger.info(f\"Debug container alive - {i+1}/10 minutes\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4a09658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/Realtime-Voting/Debug'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c9ac73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d34f0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 18:33:40,252 - INFO - Starting real-time DLT ingestion service\n",
      "2025-04-13 18:33:40,253 - INFO - Testing Kafka connection to localhost:29092\n",
      "2025-04-13 18:33:40,257 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 18:33:40,261 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <checking_api_versions_recv> [IPv6 ('::1', 29092, 0, 0)]>: Broker version identified as 2.6\n",
      "2025-04-13 18:33:40,262 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.\n",
      "2025-04-13 18:33:40,268 - INFO - Available Kafka topics: {'voters', 'votes'}\n",
      "2025-04-13 18:33:40,269 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. \n",
      "2025-04-13 18:33:40,416 - INFO - PostgreSQL connection test successful\n",
      "2025-04-13 18:33:40,417 - INFO - DLT version: 1.9.0\n",
      "2025-04-13 18:33:40,418 - INFO - Setting up continuous ingestion with destination: postgres\n",
      "2025-04-13 18:33:40,420 - INFO - Started voters ingestion thread\n",
      "2025-04-13 18:33:40,422 - INFO - Setting up continuous ingestion with destination: postgres\n",
      "2025-04-13 18:33:40,423 - INFO - Started votes ingestion thread\n",
      "2025-04-13 18:33:40,424 - INFO - Ingestion service is running. Press Ctrl+C to stop.\n",
      "2025-04-13 18:33:41,134 - INFO - Starting Kafka consumer for topic 'voters' with group 'dlt-voters-group'\n",
      "2025-04-13 18:33:41,136 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 18:33:41,144 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <checking_api_versions_recv> [IPv6 ('::1', 29092, 0, 0)]>: Broker version identified as 2.6\n",
      "2025-04-13 18:33:41,145 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.\n",
      "2025-04-13 18:33:41,147 - INFO - Updating subscribed topics to: ('voters',)\n",
      "2025-04-13 18:33:41,148 - INFO - Batch configuration: size=10, interval=100s\n",
      "2025-04-13 18:33:41,151 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 18:33:41,152 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=1 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.\n",
      "2025-04-13 18:33:41,153 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. \n",
      "2025-04-13 18:33:41,164 - INFO - Starting Kafka consumer for topic 'votes' with group 'dlt-votes-group'\n",
      "2025-04-13 18:33:41,165 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 18:33:41,170 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <checking_api_versions_recv> [IPv6 ('::1', 29092, 0, 0)]>: Broker version identified as 2.6\n",
      "2025-04-13 18:33:41,171 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.\n",
      "2025-04-13 18:33:41,172 - INFO - Updating subscribed topics to: ('votes',)\n",
      "2025-04-13 18:33:41,172 - INFO - Batch configuration: size=10, interval=100s\n",
      "2025-04-13 18:33:41,175 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 18:33:41,176 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=1 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.\n",
      "2025-04-13 18:33:41,177 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. \n",
      "2025-04-13 18:33:41,257 - INFO - Group coordinator for dlt-voters-group is BrokerMetadata(nodeId='coordinator-1', host='localhost', port=29092, rack=None)\n",
      "2025-04-13 18:33:41,257 - INFO - Discovered coordinator coordinator-1 for group dlt-voters-group\n",
      "2025-04-13 18:33:41,258 - INFO - Starting new heartbeat thread\n",
      "2025-04-13 18:33:41,259 - INFO - Revoking previously assigned partitions set() for group dlt-voters-group\n",
      "2025-04-13 18:33:41,260 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=coordinator-1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 18:33:41,261 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=coordinator-1 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.\n",
      "2025-04-13 18:33:41,280 - INFO - Group coordinator for dlt-votes-group is BrokerMetadata(nodeId='coordinator-1', host='localhost', port=29092, rack=None)\n",
      "2025-04-13 18:33:41,281 - INFO - Discovered coordinator coordinator-1 for group dlt-votes-group\n",
      "2025-04-13 18:33:41,281 - INFO - Starting new heartbeat thread\n",
      "2025-04-13 18:33:41,282 - INFO - Revoking previously assigned partitions set() for group dlt-votes-group\n",
      "2025-04-13 18:33:41,283 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=coordinator-1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-13 18:33:41,284 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=coordinator-1 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.\n",
      "2025-04-13 18:33:41,362 - INFO - (Re-)joining group dlt-voters-group\n",
      "2025-04-13 18:33:41,385 - INFO - (Re-)joining group dlt-votes-group\n",
      "2025-04-13 18:33:44,350 - INFO - Successfully joined group dlt-votes-group with generation 2\n",
      "2025-04-13 18:33:44,352 - INFO - Updated partition assignment: [TopicPartition(topic='votes', partition=0)]\n",
      "2025-04-13 18:33:44,354 - INFO - Setting newly assigned partitions {TopicPartition(topic='votes', partition=0)} for group dlt-votes-group\n",
      "2025-04-13 18:33:44,453 - INFO - Elected group leader -- performing partition assignments using range\n",
      "2025-04-13 18:33:44,457 - INFO - Successfully joined group dlt-voters-group with generation 1\n",
      "2025-04-13 18:33:44,457 - INFO - Updated partition assignment: [TopicPartition(topic='voters', partition=0)]\n",
      "2025-04-13 18:33:44,458 - INFO - Setting newly assigned partitions {TopicPartition(topic='voters', partition=0)} for group dlt-voters-group\n",
      "2025-04-13 18:33:44,467 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:44,693|[WARNING]|2770|127577421252352|dlt|job_client_impl.py|_check_table_update_hints:623|Column(s) ['\"_dlt_id\"'] with hint unique are being added to existing table voters. Several hint types may not be added to existing tables.\n",
      "2025-04-13 18:33:44,694|[WARNING]|2770|127577421252352|dlt|job_client_impl.py|_check_table_update_hints:623|Column(s) [] with hint nullable are being added to existing table voters. Several hint types may not be added to existing tables.\n",
      "2025-04-13 18:33:44,695|[WARNING]|2770|127577421252352|dlt|job_client_impl.py|_check_table_update_hints:623|Column(s) ['\"_dlt_id\"'] with hint row_key are being added to existing table voters. Several hint types may not be added to existing tables.\n",
      "2025-04-13 18:33:44,799 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.18 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569224.5428777 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:44,800 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:44,929 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569224.823034 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:44,929 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:45,040 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569224.952656 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:45,043 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:45,155 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569225.0681121 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:45,156 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:45,268 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569225.1829345 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:45,268 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:45,376 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569225.2922773 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:45,377 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:45,517 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569225.4116457 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:45,518 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:45,624 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569225.5407848 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:45,625 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:45,733 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569225.6481776 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:45,734 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:45,866 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569225.7607703 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:45,867 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:45,984 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569225.8928924 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:45,986 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:46,093 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569226.00984 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:46,093 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:46,201 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569226.1167278 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:46,202 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:46,319 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569226.2323253 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:46,320 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:46,431 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569226.3437207 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:46,432 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:46,548 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569226.4547236 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:46,549 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:46,656 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569226.573044 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:46,657 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:46,765 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569226.6799238 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:46,766 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:46,873 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569226.790159 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:46,875 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:46,993 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569226.8978477 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:46,996 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:47,133 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.05 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569227.0242975 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:47,136 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:47,377 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.05 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569227.179186 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:47,378 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:47,492 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569227.4023435 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:47,495 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:47,621 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569227.5212584 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:47,625 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:47,738 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569227.6492636 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:47,741 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:47,857 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569227.7719846 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:47,858 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:48,014 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569227.8844063 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:48,015 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:48,124 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569228.038759 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:48,125 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:48,250 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569228.1483555 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:48,252 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:48,374 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569228.275173 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:48,376 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:48,505 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569228.4157906 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:48,507 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:48,617 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569228.5328937 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:48,619 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:48,733 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569228.6415334 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:48,735 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:48,845 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569228.761069 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:48,846 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:48,953 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569228.8694465 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:48,954 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:49,061 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569228.9775257 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:49,062 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:49,168 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569229.0846703 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:49,169 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:49,284 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569229.19226 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:49,286 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:49,402 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569229.3150415 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:49,403 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:49,510 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569229.4264233 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:49,511 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:49,680 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569229.5949762 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:49,681 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:49,796 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569229.7049916 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:49,797 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:49,906 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569229.8203835 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:49,907 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:49,962 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:33:50,088 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569229.9301527 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:50,090 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:50,267|[WARNING]|2770|127577410766592|dlt|job_client_impl.py|_check_table_update_hints:623|Column(s) ['\"_dlt_id\"'] with hint unique are being added to existing table votes. Several hint types may not be added to existing tables.\n",
      "2025-04-13 18:33:50,270|[WARNING]|2770|127577410766592|dlt|job_client_impl.py|_check_table_update_hints:623|Column(s) [] with hint nullable are being added to existing table votes. Several hint types may not be added to existing tables.\n",
      "2025-04-13 18:33:50,271|[WARNING]|2770|127577410766592|dlt|job_client_impl.py|_check_table_update_hints:623|Column(s) ['\"_dlt_id\"'] with hint row_key are being added to existing table votes. Several hint types may not be added to existing tables.\n",
      "2025-04-13 18:33:50,276 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.05 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569230.1246703 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:50,278 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:50,320|[ERROR]|2770|127577282840320|dlt|load.py|w_run_job:247|Terminal exception in job votes.8727b965bf.insert_values in file /home/codespace/.dlt/pipelines/votes_pipeline/load/normalized/1744569230.1402178/started_jobs/votes.8727b965bf.0.insert_values\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/sql_client.py\", line 416, in _wrap_gen\n",
      "    return (yield from f(self, *args, **kwargs))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/impl/postgres/sql_client.py\", line 112, in execute_query\n",
      "    raise outer\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/impl/postgres/sql_client.py\", line 104, in execute_query\n",
      "    curr.execute(query, db_args)\n",
      "psycopg2.errors.ForeignKeyViolation: insert or update on table \"votes\" violates foreign key constraint \"votes_voter_id_fkey\"\n",
      "DETAIL:  Key (voter_id)=(86ea9e4f-69ab-48b9-a3aa-7033d7f0a28b) is not present in table \"voters\".\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/common/destination/client.py\", line 399, in run_managed\n",
      "    self.run()\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/insert_job_client.py\", line 28, in run\n",
      "    self._sql_client.execute_fragments(fragments)\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/impl/postgres/sql_client.py\", line 119, in execute_fragments\n",
      "    return self.execute_sql(composed, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/impl/postgres/sql_client.py\", line 90, in execute_sql\n",
      "    with self.execute_query(sql, *args, **kwargs) as curr:\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/contextlib.py\", line 137, in __enter__\n",
      "    return next(self.gen)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/sql_client.py\", line 418, in _wrap_gen\n",
      "    raise self._make_database_exception(ex)\n",
      "dlt.destinations.exceptions.DatabaseTerminalException: insert or update on table \"votes\" violates foreign key constraint \"votes_voter_id_fkey\"\n",
      "DETAIL:  Key (voter_id)=(86ea9e4f-69ab-48b9-a3aa-7033d7f0a28b) is not present in table \"voters\".\n",
      "\n",
      "2025-04-13 18:33:50,329|[ERROR]|2770|127577410766592|dlt|load.py|complete_jobs:413|Job for votes.8727b965bf.insert_values failed terminally in load 1744569230.1402178 with message insert or update on table \"votes\" violates foreign key constraint \"votes_voter_id_fkey\"\n",
      "DETAIL:  Key (voter_id)=(86ea9e4f-69ab-48b9-a3aa-7033d7f0a28b) is not present in table \"voters\".\n",
      "\n",
      "2025-04-13 18:33:50,360 - ERROR - Error processing batch: Pipeline execution failed at stage load with exception:\n",
      "\n",
      "<class 'dlt.load.exceptions.LoadClientJobFailed'>\n",
      "Job for votes.8727b965bf.insert_values failed terminally in load 1744569230.1402178 with message insert or update on table \"votes\" violates foreign key constraint \"votes_voter_id_fkey\"\n",
      "DETAIL:  Key (voter_id)=(86ea9e4f-69ab-48b9-a3aa-7033d7f0a28b) is not present in table \"voters\".\n",
      ". The package is aborted and cannot be retried.\n",
      "2025-04-13 18:33:50,362 - ERROR - Traceback (most recent call last):\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 603, in load\n",
      "    runner.run_pool(load_step.config, load_step)\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/common/runners/pool_runner.py\", line 91, in run_pool\n",
      "    while _run_func():\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/common/runners/pool_runner.py\", line 84, in _run_func\n",
      "    run_metrics = run_f.run(cast(TExecutor, pool))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/load/load.py\", line 638, in run\n",
      "    self.load_single_package(load_id, schema)\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/load/load.py\", line 597, in load_single_package\n",
      "    raise pending_exception\n",
      "dlt.load.exceptions.LoadClientJobFailed: Job for votes.8727b965bf.insert_values failed terminally in load 1744569230.1402178 with message insert or update on table \"votes\" violates foreign key constraint \"votes_voter_id_fkey\"\n",
      "DETAIL:  Key (voter_id)=(86ea9e4f-69ab-48b9-a3aa-7033d7f0a28b) is not present in table \"voters\".\n",
      ". The package is aborted and cannot be retried.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2770/1903032262.py\", line 185, in process_batch\n",
      "    info = pipeline.run(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 221, in _wrap\n",
      "    step_info = f(self, *args, **kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 270, in _wrap\n",
      "    return f(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 742, in run\n",
      "    return self.load(destination, dataset_name, credentials=credentials)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 221, in _wrap\n",
      "    step_info = f(self, *args, **kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 161, in _wrap\n",
      "    return f(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 270, in _wrap\n",
      "    return f(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 610, in load\n",
      "    raise PipelineStepFailed(\n",
      "dlt.pipeline.exceptions.PipelineStepFailed: Pipeline execution failed at stage load with exception:\n",
      "\n",
      "<class 'dlt.load.exceptions.LoadClientJobFailed'>\n",
      "Job for votes.8727b965bf.insert_values failed terminally in load 1744569230.1402178 with message insert or update on table \"votes\" violates foreign key constraint \"votes_voter_id_fkey\"\n",
      "DETAIL:  Key (voter_id)=(86ea9e4f-69ab-48b9-a3aa-7033d7f0a28b) is not present in table \"voters\".\n",
      ". The package is aborted and cannot be retried.\n",
      "\n",
      "2025-04-13 18:33:50,423 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569230.313736 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:50,425 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:50,583 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.06 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569230.448596 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:50,584 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:50,691 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569230.607598 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:50,692 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:50,803 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569230.7165577 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:50,804 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:50,910 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569230.8276565 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:50,911 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:51,018 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569230.934858 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:51,019 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:51,129 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569231.042578 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:51,130 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:51,244 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569231.1534786 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:51,245 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:51,359 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569231.2682803 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:51,361 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:51,471 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569231.3882265 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:51,473 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:51,586 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569231.4970102 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:51,587 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:51,695 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569231.6110318 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:51,696 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:51,809 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569231.7191777 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:51,810 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:51,917 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569231.8335326 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:51,918 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:52,036 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569231.9416544 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:52,039 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:52,167 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569232.0826125 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:52,168 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:52,278 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569232.190756 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:52,282 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:52,429 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.05 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569232.3049185 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:52,430 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:52,537 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569232.4529214 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:52,538 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:52,653 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569232.5613754 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:52,655 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:52,772 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569232.6857338 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:52,772 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:52,880 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569232.7963145 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:52,881 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:52,988 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569232.9034247 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:52,989 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:53,098 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569233.0121284 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:53,102 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:53,210 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569233.1253195 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:53,210 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:53,320 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569233.2336526 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:53,320 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:53,441 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569233.3437912 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:53,443 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:53,576 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569233.4861312 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:53,578 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:53,708 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569233.605379 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:53,708 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:53,818 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569233.7314022 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:53,818 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:53,955 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569233.8643339 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:53,956 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:54,063 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569233.9800334 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:54,067 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:54,202 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569234.0980206 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:54,203 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:54,313 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569234.2255933 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:54,314 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:54,424 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569234.3377595 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:54,425 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:54,531 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569234.44861 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:54,532 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:54,643 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569234.5550041 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:54,644 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:54,752 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569234.668895 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:54,753 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:54,864 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569234.7805042 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:54,867 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:54,974 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569234.8909538 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:54,975 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:55,082 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569234.9976037 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:55,083 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:55,190 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569235.1058128 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:55,190 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:55,302 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569235.213183 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:55,303 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:55,414 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569235.3260474 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:55,415 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:55,522 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569235.4383914 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:55,523 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:55,669 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569235.5460997 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:55,669 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:55,779 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569235.6926901 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:55,782 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:55,890 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569235.8057961 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:55,891 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:55,974 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:33:56,047 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.06 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569235.91455 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:56,049 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:56,144|[ERROR]|2770|127577282840320|dlt|load.py|w_run_job:247|Terminal exception in job votes.646554f061.insert_values in file /home/codespace/.dlt/pipelines/votes_pipeline/load/normalized/1744569236.0111742/started_jobs/votes.646554f061.0.insert_values\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/sql_client.py\", line 416, in _wrap_gen\n",
      "    return (yield from f(self, *args, **kwargs))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/impl/postgres/sql_client.py\", line 112, in execute_query\n",
      "    raise outer\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/impl/postgres/sql_client.py\", line 104, in execute_query\n",
      "    curr.execute(query, db_args)\n",
      "psycopg2.errors.ForeignKeyViolation: insert or update on table \"votes\" violates foreign key constraint \"votes_voter_id_fkey\"\n",
      "DETAIL:  Key (voter_id)=(5ccf4dce-79c0-413a-a8c1-a22655667fb2) is not present in table \"voters\".\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/common/destination/client.py\", line 399, in run_managed\n",
      "    self.run()\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/insert_job_client.py\", line 28, in run\n",
      "    self._sql_client.execute_fragments(fragments)\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/impl/postgres/sql_client.py\", line 119, in execute_fragments\n",
      "    return self.execute_sql(composed, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/impl/postgres/sql_client.py\", line 90, in execute_sql\n",
      "    with self.execute_query(sql, *args, **kwargs) as curr:\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/contextlib.py\", line 137, in __enter__\n",
      "    return next(self.gen)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/sql_client.py\", line 418, in _wrap_gen\n",
      "    raise self._make_database_exception(ex)\n",
      "dlt.destinations.exceptions.DatabaseTerminalException: insert or update on table \"votes\" violates foreign key constraint \"votes_voter_id_fkey\"\n",
      "DETAIL:  Key (voter_id)=(5ccf4dce-79c0-413a-a8c1-a22655667fb2) is not present in table \"voters\".\n",
      "\n",
      "2025-04-13 18:33:56,152|[ERROR]|2770|127577410766592|dlt|load.py|complete_jobs:413|Job for votes.646554f061.insert_values failed terminally in load 1744569236.0111742 with message insert or update on table \"votes\" violates foreign key constraint \"votes_voter_id_fkey\"\n",
      "DETAIL:  Key (voter_id)=(5ccf4dce-79c0-413a-a8c1-a22655667fb2) is not present in table \"voters\".\n",
      "\n",
      "2025-04-13 18:33:56,193 - ERROR - Error processing batch: Pipeline execution failed at stage load with exception:\n",
      "\n",
      "<class 'dlt.load.exceptions.LoadClientJobFailed'>\n",
      "Job for votes.646554f061.insert_values failed terminally in load 1744569236.0111742 with message insert or update on table \"votes\" violates foreign key constraint \"votes_voter_id_fkey\"\n",
      "DETAIL:  Key (voter_id)=(5ccf4dce-79c0-413a-a8c1-a22655667fb2) is not present in table \"voters\".\n",
      ". The package is aborted and cannot be retried.\n",
      "2025-04-13 18:33:56,197 - ERROR - Traceback (most recent call last):\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 603, in load\n",
      "    runner.run_pool(load_step.config, load_step)\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/common/runners/pool_runner.py\", line 91, in run_pool\n",
      "    while _run_func():\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/common/runners/pool_runner.py\", line 84, in _run_func\n",
      "    run_metrics = run_f.run(cast(TExecutor, pool))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/load/load.py\", line 638, in run\n",
      "    self.load_single_package(load_id, schema)\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/load/load.py\", line 597, in load_single_package\n",
      "    raise pending_exception\n",
      "dlt.load.exceptions.LoadClientJobFailed: Job for votes.646554f061.insert_values failed terminally in load 1744569236.0111742 with message insert or update on table \"votes\" violates foreign key constraint \"votes_voter_id_fkey\"\n",
      "DETAIL:  Key (voter_id)=(5ccf4dce-79c0-413a-a8c1-a22655667fb2) is not present in table \"voters\".\n",
      ". The package is aborted and cannot be retried.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2770/1903032262.py\", line 185, in process_batch\n",
      "    info = pipeline.run(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 221, in _wrap\n",
      "    step_info = f(self, *args, **kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 270, in _wrap\n",
      "    return f(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 742, in run\n",
      "    return self.load(destination, dataset_name, credentials=credentials)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 221, in _wrap\n",
      "    step_info = f(self, *args, **kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 161, in _wrap\n",
      "    return f(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 270, in _wrap\n",
      "    return f(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 610, in load\n",
      "    raise PipelineStepFailed(\n",
      "dlt.pipeline.exceptions.PipelineStepFailed: Pipeline execution failed at stage load with exception:\n",
      "\n",
      "<class 'dlt.load.exceptions.LoadClientJobFailed'>\n",
      "Job for votes.646554f061.insert_values failed terminally in load 1744569236.0111742 with message insert or update on table \"votes\" violates foreign key constraint \"votes_voter_id_fkey\"\n",
      "DETAIL:  Key (voter_id)=(5ccf4dce-79c0-413a-a8c1-a22655667fb2) is not present in table \"voters\".\n",
      ". The package is aborted and cannot be retried.\n",
      "\n",
      "2025-04-13 18:33:56,252 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.05 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569236.0846624 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:56,253 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:56,365 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569236.2774768 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:56,367 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:56,475 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569236.3917406 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:56,476 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:56,588 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569236.4987166 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:56,589 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:56,700 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569236.6121113 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:56,701 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:56,810 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569236.724031 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:56,811 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:56,917 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569236.8339286 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:56,918 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:57,025 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569236.9413316 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:57,026 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:57,134 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569237.0493512 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:57,136 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:57,242 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569237.158683 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:57,243 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:57,353 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569237.2676735 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:57,354 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:57,582 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.10 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569237.381954 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:57,585 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:57,740 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569237.630322 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:57,741 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:57,853 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569237.7648501 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:57,854 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:57,960 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569237.8773856 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:57,961 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:58,069 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569237.985566 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:58,070 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:58,178 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569238.0941887 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:58,179 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:58,314 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569238.202373 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:58,315 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:58,426 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569238.3387258 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:58,428 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:58,533 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569238.4506536 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:58,535 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:58,641 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569238.5577164 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:58,643 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:58,754 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569238.6708264 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:58,755 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:58,864 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569238.7800584 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:58,866 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:59,014 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569238.9158988 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:59,015 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:59,142 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569239.0396743 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:59,143 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:59,250 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569239.1665077 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:59,251 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:59,389 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569239.2737565 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:59,390 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:59,497 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569239.4134967 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:59,499 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:59,611 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569239.5231512 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:59,612 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:59,723 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569239.634668 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:59,725 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:33:59,835 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569239.7477794 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:33:59,836 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:00,008 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569239.9242969 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:00,009 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:00,119 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569240.0324082 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:00,120 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:00,230 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569240.1434152 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:00,231 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:00,363 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569240.2538886 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:00,365 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:00,479 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569240.393121 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:00,480 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:00,587 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569240.5033793 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:00,588 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:00,724 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.05 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569240.6112518 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:00,730 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:00,853 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569240.7663646 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:00,854 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:00,961 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569240.8772888 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:00,962 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:01,069 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569240.985013 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:01,070 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:01,178 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569241.0935948 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:01,179 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:01,303 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569241.2024715 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:01,304 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:01,420 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569241.3281736 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:01,422 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:01,538 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569241.4506567 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:01,539 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:01,649 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569241.5624406 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:01,650 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:01,765 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569241.6739006 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:01,767 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:01,877 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569241.7936597 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:01,878 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:01,979 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:34:01,998 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569241.9022257 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:02,000 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:02,157|[ERROR]|2770|127577282840320|dlt|load.py|w_run_job:247|Terminal exception in job votes.a0582888f6.insert_values in file /home/codespace/.dlt/pipelines/votes_pipeline/load/normalized/1744569242.021278/started_jobs/votes.a0582888f6.0.insert_values\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/sql_client.py\", line 416, in _wrap_gen\n",
      "    return (yield from f(self, *args, **kwargs))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/impl/postgres/sql_client.py\", line 112, in execute_query\n",
      "    raise outer\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/impl/postgres/sql_client.py\", line 104, in execute_query\n",
      "    curr.execute(query, db_args)\n",
      "psycopg2.errors.ForeignKeyViolation: insert or update on table \"votes\" violates foreign key constraint \"votes_voter_id_fkey\"\n",
      "DETAIL:  Key (voter_id)=(6031a350-8e8d-43c2-b86a-c4dbf486eb12) is not present in table \"voters\".\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/common/destination/client.py\", line 399, in run_managed\n",
      "    self.run()\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/insert_job_client.py\", line 28, in run\n",
      "    self._sql_client.execute_fragments(fragments)\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/impl/postgres/sql_client.py\", line 119, in execute_fragments\n",
      "    return self.execute_sql(composed, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/impl/postgres/sql_client.py\", line 90, in execute_sql\n",
      "    with self.execute_query(sql, *args, **kwargs) as curr:\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/contextlib.py\", line 137, in __enter__\n",
      "    return next(self.gen)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/destinations/sql_client.py\", line 418, in _wrap_gen\n",
      "    raise self._make_database_exception(ex)\n",
      "dlt.destinations.exceptions.DatabaseTerminalException: insert or update on table \"votes\" violates foreign key constraint \"votes_voter_id_fkey\"\n",
      "DETAIL:  Key (voter_id)=(6031a350-8e8d-43c2-b86a-c4dbf486eb12) is not present in table \"voters\".\n",
      "\n",
      "2025-04-13 18:34:02,159|[ERROR]|2770|127577410766592|dlt|load.py|complete_jobs:413|Job for votes.a0582888f6.insert_values failed terminally in load 1744569242.021278 with message insert or update on table \"votes\" violates foreign key constraint \"votes_voter_id_fkey\"\n",
      "DETAIL:  Key (voter_id)=(6031a350-8e8d-43c2-b86a-c4dbf486eb12) is not present in table \"voters\".\n",
      "\n",
      "2025-04-13 18:34:02,171 - ERROR - Error processing batch: Pipeline execution failed at stage load with exception:\n",
      "\n",
      "<class 'dlt.load.exceptions.LoadClientJobFailed'>\n",
      "Job for votes.a0582888f6.insert_values failed terminally in load 1744569242.021278 with message insert or update on table \"votes\" violates foreign key constraint \"votes_voter_id_fkey\"\n",
      "DETAIL:  Key (voter_id)=(6031a350-8e8d-43c2-b86a-c4dbf486eb12) is not present in table \"voters\".\n",
      ". The package is aborted and cannot be retried.\n",
      "2025-04-13 18:34:02,175 - ERROR - Traceback (most recent call last):\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 603, in load\n",
      "    runner.run_pool(load_step.config, load_step)\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/common/runners/pool_runner.py\", line 91, in run_pool\n",
      "    while _run_func():\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/common/runners/pool_runner.py\", line 84, in _run_func\n",
      "    run_metrics = run_f.run(cast(TExecutor, pool))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/load/load.py\", line 638, in run\n",
      "    self.load_single_package(load_id, schema)\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/load/load.py\", line 597, in load_single_package\n",
      "    raise pending_exception\n",
      "dlt.load.exceptions.LoadClientJobFailed: Job for votes.a0582888f6.insert_values failed terminally in load 1744569242.021278 with message insert or update on table \"votes\" violates foreign key constraint \"votes_voter_id_fkey\"\n",
      "DETAIL:  Key (voter_id)=(6031a350-8e8d-43c2-b86a-c4dbf486eb12) is not present in table \"voters\".\n",
      ". The package is aborted and cannot be retried.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2770/1903032262.py\", line 185, in process_batch\n",
      "    info = pipeline.run(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 221, in _wrap\n",
      "    step_info = f(self, *args, **kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 270, in _wrap\n",
      "    return f(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 742, in run\n",
      "    return self.load(destination, dataset_name, credentials=credentials)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 221, in _wrap\n",
      "    step_info = f(self, *args, **kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 161, in _wrap\n",
      "    return f(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 270, in _wrap\n",
      "    return f(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py\", line 610, in load\n",
      "    raise PipelineStepFailed(\n",
      "dlt.pipeline.exceptions.PipelineStepFailed: Pipeline execution failed at stage load with exception:\n",
      "\n",
      "<class 'dlt.load.exceptions.LoadClientJobFailed'>\n",
      "Job for votes.a0582888f6.insert_values failed terminally in load 1744569242.021278 with message insert or update on table \"votes\" violates foreign key constraint \"votes_voter_id_fkey\"\n",
      "DETAIL:  Key (voter_id)=(6031a350-8e8d-43c2-b86a-c4dbf486eb12) is not present in table \"voters\".\n",
      ". The package is aborted and cannot be retried.\n",
      "\n",
      "2025-04-13 18:34:02,188 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569242.0444298 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:02,189 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:02,301 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569242.2138581 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:02,303 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:02,442 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569242.3300185 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:02,445 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:02,554 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569242.4700263 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:02,555 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:02,703 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569242.5936937 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:02,704 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:02,838 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569242.7450833 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:02,839 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:02,947 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569242.8627634 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:02,948 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:03,056 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569242.9714649 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:03,057 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:03,165 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569243.0804214 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:03,166 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:03,276 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569243.1924422 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:03,277 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:03,387 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569243.3005419 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:03,389 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:03,496 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569243.4120631 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:03,497 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:03,604 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569243.5204396 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:03,605 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:03,712 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569243.6281223 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:03,714 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:03,836 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569243.741502 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:03,837 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:03,943 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569243.860437 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:03,944 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:04,051 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569243.9676733 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:04,052 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:04,161 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569244.0759614 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:04,163 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:04,268 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569244.1854892 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:04,269 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:04,419 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.06 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569244.297714 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:04,420 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:04,556 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569244.4451716 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:04,557 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:04,678 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569244.5905035 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:04,681 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:04,821 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.05 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569244.7038274 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:04,822 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:04,929 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569244.845097 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:04,930 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:05,039 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569244.9532533 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:05,042 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:05,148 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569245.0649831 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:05,149 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:05,257 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569245.1721697 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:05,258 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:05,368 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569245.2814217 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:05,369 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:05,479 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569245.395568 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:05,480 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:05,591 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569245.5045624 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:05,592 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:05,701 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569245.6146352 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:05,702 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:05,880 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.06 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569245.7248838 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:05,882 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:05,991 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569245.905701 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:05,993 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:06,101 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569246.0154164 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:06,103 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:06,213 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569246.1261764 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:06,215 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:06,334 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569246.2445018 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:06,335 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:06,445 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569246.3584473 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:06,446 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:06,568 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569246.4693077 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:06,570 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:06,691 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569246.6055012 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:06,693 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:06,812 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569246.7159193 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:06,813 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:06,928 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569246.8410113 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:06,930 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:07,037 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569246.9530854 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:07,038 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:07,146 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569247.0612898 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:07,147 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:07,254 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569247.1703484 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:07,255 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:07,366 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569247.2786906 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:07,367 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:07,479 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569247.3957636 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:07,480 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:07,588 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569247.5035665 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:07,590 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:07,872 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.13 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569247.612755 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:07,875 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:07,988 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:34:08,079 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.06 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569247.9276328 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:08,081 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:08,188 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.05 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569248.03292 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:08,235 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569248.1220717 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:08,237 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:08,351 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569248.2596798 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:08,352 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:08,483 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569248.3925197 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:08,484 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:08,603 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569248.5091243 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:08,605 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:08,740 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569248.6453145 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:08,741 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:08,862 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569248.7659717 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:08,863 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:08,976 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569248.886959 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:08,978 - INFO - Processing batch of 10 records for table 'voters'\n",
      "2025-04-13 18:34:09,095 - INFO - Successfully loaded batch. Load info: Pipeline voters_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569249.0026155 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:13,997 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:34:14,108 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569254.022082 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:20,006 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:34:20,115 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569260.0296469 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:26,014 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:34:26,194 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569266.0371492 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:32,024 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:34:32,145 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569272.0474594 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:38,033 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:34:38,154 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569278.056004 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:44,041 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:34:44,150 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569284.06363 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:50,050 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:34:50,157 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569290.072564 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:34:56,058 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:34:56,171 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569296.0803788 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:35:02,067 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:35:02,200 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569302.089376 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:35:08,077 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:35:08,215 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569308.1138904 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:35:14,086 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:35:14,194 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569314.1083395 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:35:20,095 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:35:20,203 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569320.1179676 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:35:26,103 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:35:26,214 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569326.1267219 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:35:32,112 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:35:32,292 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569332.2065296 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:35:38,121 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:35:38,229 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569338.1440628 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:35:44,130 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:35:44,271 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569344.1524491 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:35:50,139 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:35:50,255 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569350.16326 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:35:56,148 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:35:56,263 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569356.1707697 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:36:02,156 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:36:02,281 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569362.178709 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:36:08,164 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:36:08,272 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569368.1875358 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:36:14,175 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:36:14,286 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569374.1990266 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:36:20,187 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:36:20,303 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569380.217543 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:36:26,194 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:36:26,314 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569386.2265587 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:36:32,202 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:36:32,333 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569392.2251647 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:36:38,212 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:36:38,322 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569398.2345946 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:36:44,221 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:36:44,330 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569404.2439275 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:36:50,231 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:36:50,343 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569410.2572284 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:36:56,240 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:36:56,356 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569416.2634861 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:37:02,249 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:37:02,359 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569422.2732677 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:37:08,258 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:37:08,367 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569428.2818475 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:37:14,267 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:37:14,396 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569434.2921422 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:37:20,276 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:37:20,386 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569440.2986324 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:37:26,284 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:37:26,395 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569446.307801 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:37:32,293 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:37:32,456 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569452.3313947 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:37:38,302 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:37:38,450 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569458.3404133 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:37:44,311 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:37:44,422 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569464.335284 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:37:50,320 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:37:50,433 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569470.3472354 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:37:56,329 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:37:56,440 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569476.3541782 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:38:02,338 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:38:02,473 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569482.3614457 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:38:08,347 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:38:08,460 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569488.3697526 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:38:14,357 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:38:14,483 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569494.3812723 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:38:20,365 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:38:20,485 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569500.3952348 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:38:26,374 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:38:26,484 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569506.3973744 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:38:32,382 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:38:32,495 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569512.4064631 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:38:38,392 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:38:38,502 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569518.4149284 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:38:44,400 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:38:44,511 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569524.4233553 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:38:50,409 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:38:50,518 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569530.431904 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:38:56,417 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:38:56,530 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569536.43953 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:39:02,426 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:39:02,603 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.06 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569542.4495394 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:39:08,435 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:39:08,544 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569548.4574971 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:39:14,447 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:39:14,580 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569554.4727027 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:39:20,454 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:39:20,562 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569560.4768734 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:39:26,463 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:39:26,572 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569566.4861062 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:39:32,473 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:39:32,613 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569572.4953237 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:39:38,482 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:39:38,588 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569578.5045073 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:39:44,490 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:39:44,603 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569584.5126455 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:39:50,500 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:39:50,609 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569590.5230725 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:39:56,508 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:39:56,631 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569596.5303962 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:40:02,516 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:40:02,656 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569602.5456462 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:40:08,525 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:40:08,634 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569608.5479457 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:40:14,534 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:40:14,643 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569614.5582786 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:40:20,543 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:40:20,653 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569620.567456 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:40:26,552 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:40:26,660 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569626.5749948 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:40:32,562 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:40:32,709 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569632.5995898 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:40:38,570 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:40:38,680 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569638.5948553 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:40:44,581 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:40:44,688 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569644.6034794 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:40:50,591 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:40:50,735 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569650.6334655 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:40:56,598 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:40:56,706 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569656.6206555 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:41:02,607 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:41:02,717 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569662.6308944 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:41:08,616 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:41:08,725 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569668.6413403 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:41:14,627 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:41:14,813 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569674.6699083 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:41:20,634 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:41:20,747 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569680.657554 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:41:26,643 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:41:26,750 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569686.6659703 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:41:32,651 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:41:32,758 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569692.673356 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:41:38,659 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:41:38,767 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569698.6825433 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:41:44,669 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:41:44,796 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569704.709218 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:41:50,677 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:41:50,786 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569710.7016993 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:41:56,686 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:41:56,793 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569716.7086911 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:42:02,696 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:42:02,804 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569722.7187896 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:42:08,704 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:42:08,812 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569728.7269225 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:42:14,713 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:42:14,821 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569734.7368505 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:42:20,721 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:42:20,849 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569740.7450418 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:42:26,731 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:42:26,841 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569746.754682 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:42:32,739 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:42:32,847 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569752.7619298 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:42:38,748 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:42:38,887 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569758.7707055 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:42:44,756 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:42:44,863 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569764.778953 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:42:50,765 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:42:50,873 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569770.7879367 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:42:56,773 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:42:56,880 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569776.7961073 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:43:02,783 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:43:02,890 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569782.8059208 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:43:08,791 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:43:08,903 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569788.8144383 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:43:14,800 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:43:14,979 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569794.8229043 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:43:20,808 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:43:20,926 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569800.8381379 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:43:26,817 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:43:26,990 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569806.8483493 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:43:32,826 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:43:32,953 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569812.8492186 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:43:38,836 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:43:38,943 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569818.8585305 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:43:44,844 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:43:44,984 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569824.8662014 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:43:50,854 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:43:50,960 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569830.8761861 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:43:56,862 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:43:56,970 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569836.8850486 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:44:02,872 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:44:02,978 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569842.8938823 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:44:08,880 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:44:08,988 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569848.9028885 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:44:14,889 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:44:14,996 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569854.9117754 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:44:20,898 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:44:21,040 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569860.919961 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:44:26,906 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:44:27,014 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569866.9297156 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:44:32,915 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:44:33,029 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569872.9381902 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:44:38,923 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:44:39,032 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569878.9461777 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:44:44,933 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:44:45,042 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569884.9560494 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:44:50,941 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:44:51,049 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569890.963873 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:44:56,948 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:44:57,057 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569896.9720874 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:45:02,960 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:45:03,072 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569902.987875 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:45:08,965 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:45:09,077 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569908.9880328 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:45:14,973 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:45:15,080 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569914.9959824 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:45:20,981 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:45:21,090 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569921.0034893 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:45:26,990 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:45:27,117 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569927.0283048 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:45:32,999 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:45:33,108 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569933.0219133 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:45:39,009 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:45:39,143 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.05 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569939.0316231 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:45:45,017 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:45:45,126 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569945.0398057 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:45:51,026 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:45:51,135 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569951.0488837 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:45:57,034 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:45:57,149 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569957.0623362 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:46:03,043 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:46:03,159 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569963.0663943 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:46:09,052 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:46:09,200 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569969.0751145 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:46:15,060 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:46:15,172 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569975.0827458 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:46:21,069 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:46:21,209 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569981.092184 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:46:27,079 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:46:27,188 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569987.1024003 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:46:33,088 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:46:33,217 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569993.1163652 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:46:39,098 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:46:39,206 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744569999.1204224 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:46:45,106 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:46:45,214 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570005.12823 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:46:51,114 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:46:51,228 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570011.1375515 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:46:57,123 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:46:57,232 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570017.1473618 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:47:03,131 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:47:03,272 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570023.159652 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:47:09,140 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:47:09,247 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570029.1627235 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:47:15,149 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:47:15,257 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570035.1718976 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:47:21,159 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:47:21,270 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570041.1814756 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:47:27,167 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:47:27,297 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570047.1909282 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:47:33,175 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:47:33,283 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570053.1977487 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:47:39,184 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:47:39,292 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570059.207136 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:47:45,194 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:47:45,318 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570065.2325895 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:47:51,201 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:47:51,391 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570071.2491617 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:47:57,210 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:47:57,337 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570077.2459362 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:48:03,218 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:48:03,326 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570083.2410388 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:48:09,227 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:48:09,349 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570089.2541633 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:48:15,235 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:48:15,347 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570095.2579637 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:48:21,243 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:48:21,362 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570101.2660053 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:48:27,251 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:48:27,365 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570107.2740023 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:48:33,260 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:48:33,373 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570113.2825396 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:48:39,268 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:48:39,376 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570119.2902648 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:48:45,277 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:48:45,385 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570125.2995684 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:48:51,286 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:48:51,393 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570131.3083892 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:48:57,295 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:48:57,403 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570137.3173823 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:49:03,304 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:49:03,412 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570143.3272574 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:49:09,314 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:49:09,425 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570149.3360493 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:49:15,322 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:49:15,431 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570155.3455348 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:49:21,332 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:49:21,453 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570161.3666415 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:49:27,340 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:49:27,447 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570167.3624763 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:49:33,349 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:49:33,457 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570173.3718073 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:49:39,356 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:49:39,463 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570179.378993 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:49:45,367 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:49:45,496 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570185.4081218 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:49:51,373 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:49:51,481 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570191.3967774 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:49:57,383 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:49:57,516 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570197.4121912 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:50:03,391 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:50:03,559 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570203.4235153 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:50:09,399 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:50:09,507 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570209.4214976 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:50:15,407 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:50:15,515 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570215.4296281 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:50:21,416 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:50:21,525 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570221.4383442 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:50:27,425 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:50:27,534 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570227.447976 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:50:33,432 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:50:33,541 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570233.4552603 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:50:39,441 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:50:39,553 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570239.4663491 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:50:45,451 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:50:45,564 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570245.473414 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:50:51,461 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:50:51,621 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.05 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570251.48902 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:50:57,468 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:50:57,580 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570257.491262 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:51:03,477 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:51:03,584 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570263.4998183 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:51:09,484 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:51:09,592 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570269.5068197 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:51:15,492 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:51:15,601 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570275.5156047 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:51:21,698 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:51:21,806 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570281.721448 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:51:27,509 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:51:27,618 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570287.5317976 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:51:33,517 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:51:33,646 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570293.5396793 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:51:39,524 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:51:39,631 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570299.5469692 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:51:45,533 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:51:45,642 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570305.5563273 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:51:51,542 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:51:51,650 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570311.5653906 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:51:57,551 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:51:57,659 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570317.5738432 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:52:03,559 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:52:03,666 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570323.5821116 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:52:09,569 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:52:09,681 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570329.5919058 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:52:15,579 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:52:15,765 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570335.6402779 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:52:21,584 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:52:21,692 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570341.6066072 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:52:27,593 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:52:27,768 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570347.6841063 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:52:33,601 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:52:33,711 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570353.6247191 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:52:39,610 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:52:39,725 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570359.6338053 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:52:45,620 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:52:45,730 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570365.6426983 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:52:51,628 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:52:51,738 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570371.6501915 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:52:57,637 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:52:57,753 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570377.6648705 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:53:03,646 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:53:03,790 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570383.6681027 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:53:09,654 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:53:09,772 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.04 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570389.6783917 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:53:15,663 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:53:15,774 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570395.6856325 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:53:21,672 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:53:21,781 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570401.6950223 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:53:27,682 - INFO - Processing batch of 10 records for table 'votes'\n",
      "2025-04-13 18:53:27,792 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570407.704349 is LOADED and contains no failed jobs\n",
      "2025-04-13 18:55:08,488 - INFO - Time-based flush after 100.7s with 3 records\n",
      "2025-04-13 18:55:08,489 - INFO - Processing batch of 3 records for table 'votes'\n",
      "2025-04-13 18:55:08,638 - INFO - Successfully loaded batch. Load info: Pipeline votes_pipeline load step completed in 0.03 seconds\n",
      "1 load package(s) were loaded to destination postgres and into dataset public\n",
      "The postgres destination used postgresql://postgres:***@localhost:5432/voting_db location to store data\n",
      "Load package 1744570508.5332057 is LOADED and contains no failed jobs\n",
      "2025-04-13 19:51:21,421 - INFO - Shutdown signal received, stopping pipeline...\n",
      "2025-04-13 19:51:21,732 - INFO - Closing Kafka consumer\n",
      "2025-04-13 19:51:21,735 - INFO - Stopping heartbeat thread\n",
      "2025-04-13 19:51:22,104 - INFO - Closing Kafka consumer\n",
      "2025-04-13 19:51:22,113 - INFO - Stopping heartbeat thread\n",
      "2025-04-13 19:51:22,240 - INFO - Waiting for ingestion to complete (max 30 seconds)...\n",
      "2025-04-13 19:51:24,735 - WARNING - Heartbeat thread did not fully terminate during close\n",
      "2025-04-13 19:51:24,736 - INFO - Leaving consumer group (dlt-votes-group).\n",
      "2025-04-13 19:51:24,743 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=1 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. \n",
      "2025-04-13 19:51:24,744 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=coordinator-1 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. \n",
      "2025-04-13 19:51:25,113 - WARNING - Heartbeat thread did not fully terminate during close\n",
      "2025-04-13 19:51:25,114 - INFO - Leaving consumer group (dlt-voters-group).\n",
      "2025-04-13 19:51:25,119 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=1 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. \n",
      "2025-04-13 19:51:25,120 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=coordinator-1 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. \n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Real-time DLT pipeline for continuous data ingestion from Kafka to Postgres/BigQuery\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "import signal\n",
    "import traceback\n",
    "from kafka import KafkaConsumer, TopicPartition\n",
    "from dlt.destinations import postgres, bigquery\n",
    "from datetime import datetime\n",
    "from uuid import uuid4\n",
    "\n",
    "#os.environ['STORAGE_PREFERENCE'] = 'GCP'\n",
    "#os.environ['GCP_CREDENTIALS_PATH'] = \n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger('dlt-pipeline')\n",
    "\n",
    "# Global flag for graceful shutdown\n",
    "running = True\n",
    "\n",
    "def signal_handler(sig, frame):\n",
    "    \"\"\"Handle shutdown signals\"\"\"\n",
    "    global running\n",
    "    logger.info(\"Shutdown signal received, stopping pipeline...\")\n",
    "    running = False\n",
    "\n",
    "# Register signal handlers\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "signal.signal(signal.SIGTERM, signal_handler)\n",
    "\n",
    "def get_destination_config():\n",
    "    \"\"\"Get destination configuration based on storage preference\"\"\"\n",
    "    storage_preference = os.environ.get('STORAGE_PREFERENCE', 'postgres').upper()\n",
    "    \n",
    "    if storage_preference == 'GCP':\n",
    "        # Check if GCP credentials file path is provided\n",
    "        gcp_creds_path = os.environ.get('GCP_CREDENTIALS_PATH')\n",
    "        \n",
    "        if gcp_creds_path and os.path.exists(gcp_creds_path):\n",
    "            # Load GCP credentials from file\n",
    "            with open(gcp_creds_path, 'r') as f:\n",
    "                gcp_creds = json.load(f)\n",
    "            return 'bigquery', gcp_creds\n",
    "        else:\n",
    "            # If credentials file is not provided, try to use application default credentials\n",
    "            logger.info(\"GCP credentials file not found, using application default credentials\")\n",
    "            return 'bigquery', None\n",
    "    else:\n",
    "        # PostgreSQL connection\n",
    "        pg_host = os.environ.get('POSTGRES_HOST', 'localhost')\n",
    "        pg_port = os.environ.get('POSTGRES_PORT', '5432')\n",
    "        pg_db = os.environ.get('POSTGRES_DB', 'voting_db')\n",
    "        pg_user = os.environ.get('POSTGRES_USER', 'postgres')\n",
    "        pg_password = os.environ.get('POSTGRES_PASSWORD', 'postgres')\n",
    "        \n",
    "        connection_string = f\"postgresql://{pg_user}:{pg_password}@{pg_host}:{pg_port}/{pg_db}\"\n",
    "        return 'postgres', connection_string\n",
    "\n",
    "def create_pipeline(pipeline_name, destination_type, destination_config):\n",
    "    \"\"\"Create and configure DLT pipeline\"\"\"\n",
    "    import dlt\n",
    "    \n",
    "    # Set the appropriate destination\n",
    "    if destination_type == 'bigquery':\n",
    "        dest = bigquery(destination_config)\n",
    "    else:\n",
    "        dest = postgres(destination_config)\n",
    "    \n",
    "    # Create pipeline with incremental loading\n",
    "    pipeline = dlt.pipeline(\n",
    "        pipeline_name=pipeline_name,\n",
    "        destination=dest,\n",
    "        dataset_name='public',\n",
    "    )\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "def continuous_ingest(pipeline_name, table_name, group_id_prefix):\n",
    "    \"\"\"Continuously ingest data from Kafka to the destination\"\"\"\n",
    "    global running\n",
    "    \n",
    "    # Get destination configuration\n",
    "    destination_type, destination_config = get_destination_config()\n",
    "    logger.info(f\"Setting up continuous ingestion with destination: {destination_type}\")\n",
    "    \n",
    "    # Create DLT pipeline\n",
    "    import dlt\n",
    "    pipeline = create_pipeline(pipeline_name, destination_type, destination_config)\n",
    "    \n",
    "    # Kafka configuration\n",
    "    bootstrap_servers = os.environ.get('KAFKA_BOOTSTRAP_SERVERS', 'localhost:29092')\n",
    "    topic_type = \"VOTES\" if table_name.lower() == \"votes\" else \"VOTERS\"\n",
    "    topic = os.environ.get(f'KAFKA_{topic_type}_TOPIC', topic_type.lower())\n",
    "    #topic = os.environ.get(f'KAFKA_{\"VOTES\" if \"vote\" in table_name.lower() else \"VOTERS\"}_TOPIC', \n",
    "    #                      'votes' if 'vote' in table_name.lower() else 'voters')\n",
    "    \n",
    "    # Use a consistent group_id for offset tracking between restarts\n",
    "    # But allow multiple instances with different IDs if needed\n",
    "    instance_id = os.environ.get('INSTANCE_ID', '')\n",
    "    group_id = f\"{group_id_prefix}-{instance_id}\" if instance_id else group_id_prefix\n",
    "    \n",
    "    logger.info(f\"Starting Kafka consumer for topic '{topic}' with group '{group_id}'\")\n",
    "    \n",
    "    # Create consumer without timeout to enable continuous processing\n",
    "    consumer = KafkaConsumer(\n",
    "        topic,\n",
    "        bootstrap_servers=[bootstrap_servers],\n",
    "        auto_offset_reset='earliest',  # Start from earliest unprocessed message\n",
    "        value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n",
    "        group_id=group_id,\n",
    "        enable_auto_commit=True,  # Automatically commit offsets\n",
    "        auto_commit_interval_ms=15000,  # Commit every 15 seconds\n",
    "    )\n",
    "    \n",
    "    # Batch size configuration\n",
    "    batch_size = int(os.environ.get('BATCH_SIZE', '10')) #from 100\n",
    "    max_batch_interval_seconds = int(os.environ.get('MAX_BATCH_INTERVAL_SECONDS', '100')) #30\n",
    "    \n",
    "    logger.info(f\"Batch configuration: size={batch_size}, interval={max_batch_interval_seconds}s\")\n",
    "    \n",
    "    batch_buffer = []\n",
    "    last_flush_time = time.time()\n",
    "    \n",
    "    # Main ingestion loop\n",
    "    try:\n",
    "        while running:\n",
    "            # Poll for messages with a timeout to avoid blocking indefinitely\n",
    "            messages = consumer.poll(timeout_ms=1000, max_records=batch_size)\n",
    "            \n",
    "            current_time = time.time()\n",
    "            time_since_last_flush = current_time - last_flush_time\n",
    "            \n",
    "            if messages:\n",
    "                # Process received messages\n",
    "                for tp, msgs in messages.items():\n",
    "                    for msg in msgs:\n",
    "                        # Add message to the batch buffer\n",
    "                        batch_buffer.append(msg.value)\n",
    "                        \n",
    "                        # If batch is full, process it\n",
    "                        if len(batch_buffer) >= batch_size:\n",
    "                            process_batch(pipeline, batch_buffer, table_name)\n",
    "                            batch_buffer = []\n",
    "                            last_flush_time = time.time()\n",
    "            \n",
    "            # Also flush if max time has passed since last flush\n",
    "            if batch_buffer and time_since_last_flush >= max_batch_interval_seconds:\n",
    "                logger.info(f\"Time-based flush after {time_since_last_flush:.1f}s with {len(batch_buffer)} records\")\n",
    "                process_batch(pipeline, batch_buffer, table_name)\n",
    "                batch_buffer = []\n",
    "                last_flush_time = time.time()\n",
    "                \n",
    "            # Small sleep to prevent CPU spinning when idle\n",
    "            if not messages:\n",
    "                time.sleep(0.1)\n",
    "                \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in continuous ingestion: {str(e)}\")\n",
    "        logger.error(traceback.format_exc())\n",
    "    finally:\n",
    "        # Process any remaining records in the buffer\n",
    "        if batch_buffer:\n",
    "            logger.info(f\"Processing {len(batch_buffer)} remaining records before shutdown\")\n",
    "            process_batch(pipeline, batch_buffer, table_name)\n",
    "            \n",
    "        # Clean up resources\n",
    "        logger.info(\"Closing Kafka consumer\")\n",
    "        consumer.close()\n",
    "\n",
    "def process_batch(pipeline, batch, table_name):\n",
    "    \"\"\"Process a batch of records with DLT\"\"\"\n",
    "    if not batch:\n",
    "        return\n",
    "    \n",
    "    logger.info(f\"Processing batch of {len(batch)} records for table '{table_name}'\")\n",
    "    \n",
    "    try:\n",
    "        # Run the pipeline with the batch data\n",
    "        info = pipeline.run(\n",
    "            batch,\n",
    "            table_name=table_name,\n",
    "            write_disposition='append'\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Successfully loaded batch. Load info: {info}\")\n",
    "        \n",
    "        # Check for errors\n",
    "        if hasattr(info, 'load_packages') and info.load_packages:\n",
    "            if hasattr(info.load_packages, 'failed_rows_count') and info.load_packages.failed_rows_count > 0:\n",
    "                logger.warning(f\"Failed to load {info.load_packages.failed_rows_count} rows\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing batch: {str(e)}\")\n",
    "        logger.error(traceback.format_exc())\n",
    "\n",
    "def test_components():\n",
    "    \"\"\"Test basic components before starting continuous ingestion\"\"\"\n",
    "    # Test Kafka connection\n",
    "    bootstrap_servers = os.environ.get('KAFKA_BOOTSTRAP_SERVERS', 'localhost:29092')\n",
    "    logger.info(f\"Testing Kafka connection to {bootstrap_servers}\")\n",
    "    \n",
    "    try:\n",
    "        consumer = KafkaConsumer(\n",
    "            bootstrap_servers=[bootstrap_servers],\n",
    "            group_id='test-group',\n",
    "            consumer_timeout_ms=5000\n",
    "        )\n",
    "        \n",
    "        topics = consumer.topics()\n",
    "        logger.info(f\"Available Kafka topics: {topics}\")\n",
    "        consumer.close()\n",
    "        \n",
    "        # Test database connection\n",
    "        destination_type, destination_config = get_destination_config()\n",
    "        if destination_type == 'postgres':\n",
    "            import psycopg2\n",
    "            pg_host = os.environ.get('POSTGRES_HOST', 'localhost')\n",
    "            pg_port = os.environ.get('POSTGRES_PORT', '5432')\n",
    "            pg_db = os.environ.get('POSTGRES_DB', 'voting_db')\n",
    "            pg_user = os.environ.get('POSTGRES_USER', 'postgres')\n",
    "            pg_password = os.environ.get('POSTGRES_PASSWORD', 'postgres')\n",
    "            \n",
    "            conn = psycopg2.connect(\n",
    "                host=pg_host,\n",
    "                port=pg_port,\n",
    "                dbname=pg_db,\n",
    "                user=pg_user,\n",
    "                password=pg_password\n",
    "            )\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"SELECT 1\")\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            logger.info(\"PostgreSQL connection test successful\")\n",
    "        \n",
    "        # Test DLT installation\n",
    "        import dlt\n",
    "        logger.info(f\"DLT version: {dlt.__version__}\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Component tests failed: {str(e)}\")\n",
    "        logger.error(traceback.format_exc())\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main entry point for the continuous ingestion service\"\"\"\n",
    "    logger.info(\"Starting real-time DLT ingestion service\")\n",
    "    \n",
    "    # Test components first\n",
    "    if not test_components():\n",
    "        logger.error(\"Component tests failed. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Get configuration for which data to ingest\n",
    "    pipeline_name = os.environ.get('PIPELINE_NAME', 'voting_data')\n",
    "    ingest_voters = os.environ.get('INGEST_VOTERS', 'true').lower() == 'true'\n",
    "    ingest_votes = os.environ.get('INGEST_VOTES', 'true').lower() == 'true'\n",
    "    \n",
    "    # Start ingestion processes\n",
    "    if ingest_voters:\n",
    "        import threading\n",
    "        pipeline_name = 'voters'\n",
    "        voters_thread = threading.Thread(\n",
    "            target=continuous_ingest,\n",
    "            args=('voters_pipeline', 'voters', 'dlt-voters-group'),\n",
    "            daemon=True\n",
    "        )\n",
    "        voters_thread.start()\n",
    "        logger.info(\"Started voters ingestion thread\")\n",
    "    \n",
    "    if ingest_votes:\n",
    "        import threading\n",
    "        pipeline_name = 'votes'\n",
    "        votes_thread = threading.Thread(\n",
    "            target=continuous_ingest,\n",
    "            args=('votes_pipeline', 'votes', 'dlt-votes-group'),\n",
    "            daemon=True\n",
    "        )\n",
    "        votes_thread.start()\n",
    "        logger.info(\"Started votes ingestion thread\")\n",
    "    \n",
    "    # Keep main thread alive to allow the ingestion to continue\n",
    "    logger.info(\"Ingestion service is running. Press Ctrl+C to stop.\")\n",
    "    try:\n",
    "        while running:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        logger.info(\"Keyboard interrupt received, stopping service...\")\n",
    "    \n",
    "    # Wait for a clean shutdown\n",
    "    logger.info(\"Waiting for ingestion to complete (max 30 seconds)...\")\n",
    "    shutdown_start = time.time()\n",
    "    while time.time() - shutdown_start < 30 and any(t.is_alive() for t in threading.enumerate() if t != threading.current_thread()):\n",
    "        time.sleep(1)\n",
    "    \n",
    "    logger.info(\"DLT ingestion service stopped\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22c7a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b464d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data-generator:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: docker/Dockerfile.generator\n",
    "    volumes:\n",
    "      - ./data_generator:/app/data_generator\n",
    "    environment:\n",
    "      - VOTERS_COUNT=1000\n",
    "      - VOTES_PER_MINUTE=100\n",
    "      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092\n",
    "    networks:\n",
    "      - voting-network\n",
    "    depends_on:\n",
    "      - kafka\n",
    "    command: python -m data_generator.voter_gen2\n",
    "\n",
    "  vote-simulator:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: docker/Dockerfile.generator\n",
    "    volumes:\n",
    "      - ./data_generator:/app/data_generator\n",
    "    environment:\n",
    "      - VOTES_PER_MINUTE=100\n",
    "      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092\n",
    "    networks:\n",
    "      - voting-network\n",
    "    depends_on:\n",
    "      - kafka\n",
    "      - data-generator\n",
    "    #command: python -m data_generator.vote_sim2\n",
    "    command: python -m data_generator.real_vote_simulator\n",
    "    #command: python -m data_generator.real_vote_sim2\n",
    "\n",
    "  # Kafka infrastructure\n",
    "  zookeeper:\n",
    "    image: confluentinc/cp-zookeeper:7.5.0\n",
    "    ports:\n",
    "      - \"2181:2181\"\n",
    "    environment:\n",
    "      ZOOKEEPER_CLIENT_PORT: 2181\n",
    "      ZOOKEEPER_TICK_TIME: 2000\n",
    "      KAFKA_HEAP_OPTS: \"-Xmx512M -Xms256M\"\n",
    "    networks:\n",
    "      - voting-network\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"nc\", \"-z\", \"localhost\", \"2181\"]\n",
    "      interval: 5s\n",
    "      timeout: 10s\n",
    "      retries: 5\n",
    "\n",
    "  kafka:\n",
    "    image: confluentinc/cp-kafka:7.5.0\n",
    "    ports:\n",
    "      - \"9092:9092\"\n",
    "      - \"29092:29092\"\n",
    "    environment:\n",
    "      KAFKA_BROKER_ID: 1\n",
    "      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\n",
    "      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,HOST://localhost:29092\n",
    "      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,HOST:PLAINTEXT\n",
    "      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,HOST://0.0.0.0:29092\n",
    "      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT\n",
    "      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1\n",
    "      KAFKA_CREATE_TOPICS: \"votes:4:1,voters:1:1\"\n",
    "    networks:\n",
    "      - voting-network\n",
    "    depends_on:\n",
    "      - zookeeper\n",
    "\n",
    "  # DLT pipeline for data ingestion\n",
    "  dlt-pipeline:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: docker/Dockerfile.ingestion\n",
    "    volumes:\n",
    "      - ./ingestion:/app/ingestion\n",
    "      - ~/.dlt:/root/.dlt\n",
    "    environment:\n",
    "      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092\n",
    "      - STORAGE_PREFERENCE=GCP  # or GCP\n",
    "      - POSTGRES_HOST=postgres\n",
    "      - POSTGRES_PORT=5432\n",
    "      - POSTGRES_DB=voting_db\n",
    "      - POSTGRES_USER=postgres\n",
    "      - POSTGRES_PASSWORD=postgres\n",
    "      # Add for GCP if needed\n",
    "      - GCP_CREDENTIALS_PATH=/workspaces/Realtime-Voting/dprof-dezoomfinal-b4d188529d18.json\n",
    "    networks:\n",
    "      - voting-network\n",
    "    depends_on:\n",
    "      - kafka\n",
    "      - postgres\n",
    "    #command: python -m ingestion.dlt_pipeline.voter_pipeline2\n",
    "    #command: python ingestion/dlt_pipeline/voter_pipeline.py\n",
    "    command: python ingestion/dlt_pipeline/real_dlt.py\n",
    "postgres:\n",
    "    image: postgres:14\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "    environment:\n",
    "      POSTGRES_USER: postgres\n",
    "      POSTGRES_PASSWORD: postgres\n",
    "      POSTGRES_MULTIPLE_DATABASES: \"voting_db,kestra\"\n",
    "      POSTGRES_KESTRA_USER: kestra\n",
    "      POSTGRES_KESTRA_PASSWORD: k3str4\n",
    "    volumes:\n",
    "      - postgres-data:/var/lib/postgresql/data\n",
    "      - ./docker/postgres-init.sh:/docker-entrypoint-initdb.d/postgres-init.sh\n",
    "    networks:\n",
    "      - voting-network\n",
    "\n",
    "  # pgweb - PostgreSQL web interface\n",
    "  pgweb:\n",
    "    image: sosedoff/pgweb\n",
    "    ports:\n",
    "      - \"8085:8081\"\n",
    "    environment:\n",
    "      - DATABASE_URL=postgres://postgres:postgres@postgres:5432/voting_db?sslmode=disable\n",
    "    networks:\n",
    "      - voting-network\n",
    "    depends_on:\n",
    "      - postgres\n",
    "    restart: unless-stopped\n",
    "\n",
    "networks:\n",
    "  voting-network:\n",
    "    driver: bridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade28cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6acbb35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bda1af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://postgres:postgres@localhost:5432/voting_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ce2e1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x704bcd5a0b90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1b8428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ.get('KAFKA_BOOTSTRAP_SERVERS', '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60d48fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-12 19:33:16,371 - INFO - Creating test consumer...\n",
      "2025-04-12 19:33:16,374 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-12 19:33:16,378 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <checking_api_versions_recv> [IPv6 ('::1', 29092, 0, 0)]>: Broker version identified as 2.6\n",
      "2025-04-12 19:33:16,379 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.\n",
      "2025-04-12 19:33:16,380 - INFO - Listing topics...\n",
      "2025-04-12 19:33:16,384 - INFO - Available topics: {'voters', 'votes'}\n",
      "2025-04-12 19:33:16,385 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. \n",
      "2025-04-12 19:33:16,386 - INFO - Kafka connection test successful\n"
     ]
    }
   ],
   "source": [
    "bootstrap_servers = os.environ.get('KAFKA_BOOTSTRAP_SERVERS', 'localhost:29092')\n",
    "logger.info(\"Creating test consumer...\")\n",
    "consumer = KafkaConsumer(\n",
    "    bootstrap_servers=[bootstrap_servers],\n",
    "    group_id='debug-group',\n",
    "    auto_offset_reset='earliest',\n",
    "    consumer_timeout_ms=10000\n",
    ")\n",
    "\n",
    "logger.info(\"Listing topics...\")\n",
    "topics = consumer.topics()\n",
    "logger.info(f\"Available topics: {topics}\")\n",
    "\n",
    "consumer.close()\n",
    "logger.info(\"Kafka connection test successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "390e95e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ad48bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"ny_taxi_pipeline\",\n",
    "    destination=\"duckdb\",\n",
    "    dataset_name=\"ny_taxi_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9206bda",
   "metadata": {},
   "outputs": [
    {
     "ename": "CatalogException",
     "evalue": "Catalog Error: SET search_path: No catalog + schema named \"ny_taxi_data\" found.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCatalogException\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m conn = duckdb.connect(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline.pipeline_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.duckdb\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Set search path to the dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSET search_path = \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Describe the dataset\u001b[39;00m\n\u001b[32m     12\u001b[39m conn.sql(\u001b[33m\"\u001b[39m\u001b[33mDESCRIBE\u001b[39m\u001b[33m\"\u001b[39m).df()\n",
      "\u001b[31mCatalogException\u001b[39m: Catalog Error: SET search_path: No catalog + schema named \"ny_taxi_data\" found."
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "# A database '.duckdb' was created in working directory so just connect to it\n",
    "\n",
    "# Connect to the DuckDB database\n",
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "\n",
    "# Set search path to the dataset\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "\n",
    "# Describe the dataset\n",
    "conn.sql(\"DESCRIBE\").df()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29597d19",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LoadInfo' object has no attribute 'load_package'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m load_info = pipeline.run(get_taxi_data(), table_name=\u001b[33m\"\u001b[39m\u001b[33myellow_taxi_trips\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Print the load information\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mload_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_package\u001b[49m.count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows to table \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mload_info.load_package.table_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'LoadInfo' object has no attribute 'load_package'"
     ]
    }
   ],
   "source": [
    "import dlt\n",
    "#from dlt.sources.helpers import requests_get\n",
    "import pandas as pd\n",
    "\n",
    "# Create the pipeline\n",
    "# pipeline = dlt.pipeline(\n",
    "#     pipeline_name=\"ny_taxi_pipeline\",\n",
    "#     destination=\"duckdb\",\n",
    "#     dataset_name=\"ny_taxi_data\"\n",
    "# )\n",
    "\n",
    "# Let's get a small sample of NYC taxi data\n",
    "def get_taxi_data():\n",
    "    url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\"\n",
    "    # Limit to a small sample for demonstration\n",
    "    df = pd.read_parquet(url, engine=\"pyarrow\")\n",
    "    return df.head(1000).to_dict(orient=\"records\")\n",
    "\n",
    "# Run the pipeline to load the data\n",
    "load_info = pipeline.run(get_taxi_data(), table_name=\"yellow_taxi_trips\")\n",
    "\n",
    "# Print the load information\n",
    "print(f\"Loaded {load_info.load_package.count} rows to table {load_info.load_package.table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cdbd9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tables:\n",
      "[('yellow_taxi_trips',), ('_dlt_loads',), ('_dlt_pipeline_state',), ('_dlt_version',)]\n",
      "\n",
      "Sample data:\n",
      "   vendor_id      tpep_pickup_datetime     tpep_dropoff_datetime  \\\n",
      "0          2 2023-01-01 00:32:10+00:00 2023-01-01 00:40:36+00:00   \n",
      "1          2 2023-01-01 00:55:08+00:00 2023-01-01 01:01:27+00:00   \n",
      "2          2 2023-01-01 00:25:04+00:00 2023-01-01 00:37:49+00:00   \n",
      "3          1 2023-01-01 00:03:48+00:00 2023-01-01 00:13:25+00:00   \n",
      "4          2 2023-01-01 00:10:29+00:00 2023-01-01 00:21:19+00:00   \n",
      "\n",
      "   passenger_count  trip_distance  ratecode_id store_and_fwd_flag  \\\n",
      "0              1.0           0.97          1.0                  N   \n",
      "1              1.0           1.10          1.0                  N   \n",
      "2              1.0           2.51          1.0                  N   \n",
      "3              0.0           1.90          1.0                  N   \n",
      "4              1.0           1.43          1.0                  N   \n",
      "\n",
      "   pu_location_id  do_location_id  payment_type  ...  extra  mta_tax  \\\n",
      "0             161             141             2  ...   1.00      0.5   \n",
      "1              43             237             1  ...   1.00      0.5   \n",
      "2              48             238             1  ...   1.00      0.5   \n",
      "3             138               7             1  ...   7.25      0.5   \n",
      "4             107              79             1  ...   1.00      0.5   \n",
      "\n",
      "   tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
      "0        0.00           0.0                    1.0         14.30   \n",
      "1        4.00           0.0                    1.0         16.90   \n",
      "2       15.00           0.0                    1.0         34.90   \n",
      "3        0.00           0.0                    1.0         20.85   \n",
      "4        3.28           0.0                    1.0         19.68   \n",
      "\n",
      "   congestion_surcharge  airport_fee        _dlt_load_id         _dlt_id  \n",
      "0                   2.5         0.00  1744487688.5879216  VEn1AdGjBCYRMw  \n",
      "1                   2.5         0.00  1744487688.5879216  lwTdlloubdAsXg  \n",
      "2                   2.5         0.00  1744487688.5879216  N3iB1e9b+FoaaQ  \n",
      "3                   0.0         1.25  1744487688.5879216  tWnRGDt59An5EA  \n",
      "4                   2.5         0.00  1744487688.5879216  k6Fh5xkQQw+cyw  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "Average trip distance by payment type:\n",
      "   payment_type  avg_distance  trip_count\n",
      "0             2      3.028048         210\n",
      "1             1      2.971464         772\n",
      "2             3      1.860000           8\n",
      "3             4      1.720000          10\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "# Connect to the DuckDB database created by DLT\n",
    "# By default, it will be in .dlt/duckdb/ny_taxi_data.duckdb\n",
    "conn = duckdb.connect('/workspaces/Realtime-Voting/Debug/ny_taxi_pipeline.duckdb')\n",
    "\n",
    "# View the available tables\n",
    "print(\"Available tables:\")\n",
    "print(conn.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema='ny_taxi_data'\").fetchall())\n",
    "\n",
    "# Query the data\n",
    "print(\"\\nSample data:\")\n",
    "result = conn.execute(\"\"\"\n",
    "    SELECT * FROM ny_taxi_data.yellow_taxi_trips LIMIT 5\n",
    "\"\"\").fetchall()\n",
    "\n",
    "# Get column names\n",
    "columns = conn.execute(\"\"\"\n",
    "    SELECT column_name \n",
    "    FROM information_schema.columns \n",
    "    WHERE table_schema='ny_taxi_data' \n",
    "    AND table_name='yellow_taxi_trips'\n",
    "\"\"\").fetchall()\n",
    "column_names = [col[0] for col in columns]\n",
    "\n",
    "# Create a DataFrame to display the results nicely\n",
    "result_df = pd.DataFrame(result, columns=column_names)\n",
    "print(result_df)\n",
    "\n",
    "# Run a simple aggregation query\n",
    "print(\"\\nAverage trip distance by payment type:\")\n",
    "agg_result = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        payment_type, \n",
    "        AVG(trip_distance) as avg_distance,\n",
    "        COUNT(*) as trip_count\n",
    "    FROM ny_taxi_data.yellow_taxi_trips\n",
    "    GROUP BY payment_type\n",
    "    ORDER BY avg_distance DESC\n",
    "\"\"\").fetchdf()\n",
    "print(agg_result)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70a4710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import dlt\n",
    "\n",
    "def kafka_voters_source():\n",
    "    \"\"\"Source function that reads voters from Kafka\"\"\"\n",
    "    consumer = KafkaConsumer(\n",
    "        'voters',\n",
    "        bootstrap_servers=['localhost:29092'],\n",
    "        auto_offset_reset='earliest',\n",
    "        value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n",
    "        group_id='dlt-voter-group'\n",
    "    )\n",
    "    \n",
    "    for message in consumer:\n",
    "        yield message.value\n",
    "\n",
    "def kafka_votes_source():\n",
    "    \"\"\"Source function that reads votes from Kafka\"\"\"\n",
    "    consumer = KafkaConsumer(\n",
    "        'votes',\n",
    "        bootstrap_servers=['localhost:29092'],\n",
    "        auto_offset_reset='earliest',\n",
    "        value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n",
    "        group_id='dlt-votes-group'\n",
    "    )\n",
    "    \n",
    "    for message in consumer:\n",
    "        yield message.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7dae662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_destination_config():\n",
    "    \"\"\"Get destination configuration based on storage preference\"\"\"\n",
    "    storage_preference = os.environ.get('STORAGE_PREFERENCE', 'postgres').upper()\n",
    "    \n",
    "    if storage_preference == 'GCP':\n",
    "        # Check if GCP credentials file path is provided\n",
    "        gcp_creds_path = os.environ.get('GCP_CREDENTIALS_PATH')\n",
    "        \n",
    "        if gcp_creds_path and os.path.exists(gcp_creds_path):\n",
    "            # Load GCP credentials from file\n",
    "            with open(gcp_creds_path, 'r') as f:\n",
    "                gcp_creds = json.load(f)\n",
    "            return 'bigquery', gcp_creds\n",
    "        else:\n",
    "            # If credentials file is not provided, try to use application default credentials\n",
    "            print(\"GCP credentials file not found, using application default credentials\")\n",
    "            return 'bigquery', None\n",
    "    else:\n",
    "        # PostgreSQL connection\n",
    "        pg_host = os.environ.get('POSTGRES_HOST', 'localhost')\n",
    "        pg_port = os.environ.get('POSTGRES_PORT', '5432')\n",
    "        pg_db = os.environ.get('POSTGRES_DB', 'voting_db')\n",
    "        pg_user = os.environ.get('POSTGRES_USER', 'postgres')\n",
    "        pg_password = os.environ.get('POSTGRES_PASSWORD', 'postgres')\n",
    "        \n",
    "        connection_string = f\"postgresql://{pg_user}:{pg_password}@{pg_host}:{pg_port}/{pg_db}\"\n",
    "        return 'postgres', connection_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf455602",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = 'voters'\n",
    "table_name = 'voters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fe2608e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-12 20:11:32,251 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-12 20:11:32,255 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <checking_api_versions_recv> [IPv6 ('::1', 29092, 0, 0)]>: Broker version identified as 2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-12 20:11:32,256 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.\n",
      "2025-04-12 20:11:32,258 - INFO - Updating subscribed topics to: ('voters',)\n",
      "2025-04-12 20:11:32,263 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-12 20:11:32,265 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=1 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.\n",
      "2025-04-12 20:11:32,265 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. \n",
      "2025-04-12 20:11:32,368 - INFO - Group coordinator for dlt-voter-group is BrokerMetadata(nodeId='coordinator-1', host='localhost', port=29092, rack=None)\n",
      "2025-04-12 20:11:32,373 - INFO - Discovered coordinator coordinator-1 for group dlt-voter-group\n",
      "2025-04-12 20:11:32,374 - INFO - Starting new heartbeat thread\n",
      "2025-04-12 20:11:32,375 - INFO - Revoking previously assigned partitions set() for group dlt-voter-group\n",
      "2025-04-12 20:11:32,376 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=coordinator-1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]\n",
      "2025-04-12 20:11:32,378 - INFO - <BrokerConnection client_id=kafka-python-2.1.5, node_id=coordinator-1 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.\n",
      "2025-04-12 20:11:32,479 - INFO - (Re-)joining group dlt-voter-group\n",
      "2025-04-12 20:11:33,956 - INFO - Successfully joined group dlt-voter-group with generation 2\n",
      "2025-04-12 20:11:33,958 - INFO - Updated partition assignment: [TopicPartition(topic='voters', partition=0)]\n",
      "2025-04-12 20:11:33,959 - INFO - Setting newly assigned partitions {TopicPartition(topic='voters', partition=0)} for group dlt-voter-group\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      2\u001b[39m destination_type, destination_config = get_destination_config()\n\u001b[32m      3\u001b[39m pipeline = dlt.pipeline(\n\u001b[32m      4\u001b[39m     pipeline_name=pipeline_name,\n\u001b[32m      5\u001b[39m     destination=postgres(destination_config),\n\u001b[32m      6\u001b[39m     dataset_name=\u001b[33m'\u001b[39m\u001b[33mpublic\u001b[39m\u001b[33m'\u001b[39m,  \u001b[38;5;66;03m# Use 'public' schema or whatever schema your tables are in\u001b[39;00m\n\u001b[32m      7\u001b[39m     dev_mode=\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# This forces DLT to recreate all internal state tables\u001b[39;00m\n\u001b[32m      8\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m info = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkafka_voters_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwrite_disposition\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mappend\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#merge_key=None,  # Set this to your primary key if you want upsert behavior\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#if_exists='append'  # 'append' will add to existing tables, 'replace' would drop and recreate\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py:221\u001b[39m, in \u001b[36mwith_runtime_trace.<locals>.decorator.<locals>._wrap\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trace:\n\u001b[32m    219\u001b[39m         trace_step = start_trace_step(trace, cast(TPipelineStep, f.\u001b[34m__name__\u001b[39m), \u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     step_info = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m step_info\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py:270\u001b[39m, in \u001b[36mwith_config_section.<locals>.decorator.<locals>._wrap\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrap\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, *args: Any, **kwargs: Any) -> Any:\n\u001b[32m    264\u001b[39m     \u001b[38;5;66;03m# add section context to the container to be used by all configuration without explicit sections resolution\u001b[39;00m\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inject_section(\n\u001b[32m    266\u001b[39m         ConfigSectionContext(\n\u001b[32m    267\u001b[39m             pipeline_name=\u001b[38;5;28mself\u001b[39m.pipeline_name, sections=sections, merge_style=merge_func\n\u001b[32m    268\u001b[39m         )\n\u001b[32m    269\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py:730\u001b[39m, in \u001b[36mPipeline.run\u001b[39m\u001b[34m(self, data, destination, staging, dataset_name, credentials, table_name, write_disposition, columns, primary_key, schema, loader_file_format, table_format, schema_contract, refresh)\u001b[39m\n\u001b[32m    728\u001b[39m \u001b[38;5;66;03m# extract from the source\u001b[39;00m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m730\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwrite_disposition\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrite_disposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprimary_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprimary_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m        \u001b[49m\u001b[43mschema_contract\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema_contract\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    741\u001b[39m     \u001b[38;5;28mself\u001b[39m.normalize(loader_file_format=loader_file_format)\n\u001b[32m    742\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.load(destination, dataset_name, credentials=credentials)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py:221\u001b[39m, in \u001b[36mwith_runtime_trace.<locals>.decorator.<locals>._wrap\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trace:\n\u001b[32m    219\u001b[39m         trace_step = start_trace_step(trace, cast(TPipelineStep, f.\u001b[34m__name__\u001b[39m), \u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     step_info = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m step_info\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py:175\u001b[39m, in \u001b[36mwith_schemas_sync.<locals>._wrap\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m     \u001b[38;5;28mself\u001b[39m._schema_storage.commit_live_schema(name)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     rv = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    177\u001b[39m     \u001b[38;5;66;03m# because we committed live schema before calling f, we may safely\u001b[39;00m\n\u001b[32m    178\u001b[39m     \u001b[38;5;66;03m# drop all changes in live schemas\u001b[39;00m\n\u001b[32m    179\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m._schema_storage.live_schemas.keys()):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py:161\u001b[39m, in \u001b[36mwith_state_sync.<locals>.decorator.<locals>._wrap\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    159\u001b[39m should_extract_state = may_extract_state \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.restore_from_destination\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.managed_state(extract_state=should_extract_state):\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py:270\u001b[39m, in \u001b[36mwith_config_section.<locals>.decorator.<locals>._wrap\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrap\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, *args: Any, **kwargs: Any) -> Any:\n\u001b[32m    264\u001b[39m     \u001b[38;5;66;03m# add section context to the container to be used by all configuration without explicit sections resolution\u001b[39;00m\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inject_section(\n\u001b[32m    266\u001b[39m         ConfigSectionContext(\n\u001b[32m    267\u001b[39m             pipeline_name=\u001b[38;5;28mself\u001b[39m.pipeline_name, sections=sections, merge_style=merge_func\n\u001b[32m    268\u001b[39m         )\n\u001b[32m    269\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py:466\u001b[39m, in \u001b[36mPipeline.extract\u001b[39m\u001b[34m(self, data, table_name, parent_table_name, write_disposition, columns, primary_key, schema, max_parallel_items, workers, table_format, schema_contract, refresh)\u001b[39m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m source.exhausted:\n\u001b[32m    464\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SourceExhausted(source.name)\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extract_source\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextract_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_parallel_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;66;03m# this will update state version hash so it will not be extracted again by with_state_sync\u001b[39;00m\n\u001b[32m    475\u001b[39m \u001b[38;5;28mself\u001b[39m._bump_version_and_extract_state(\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m._container[StateInjectableContext].state,\n\u001b[32m    477\u001b[39m     \u001b[38;5;28mself\u001b[39m.config.restore_from_destination,\n\u001b[32m    478\u001b[39m     extract_step,\n\u001b[32m    479\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/pipeline/pipeline.py:1238\u001b[39m, in \u001b[36mPipeline._extract_source\u001b[39m\u001b[34m(self, extract, source, max_parallel_items, workers, refresh, load_package_state_update)\u001b[39m\n\u001b[32m   1235\u001b[39m source.schema.update_normalizers()\n\u001b[32m   1237\u001b[39m \u001b[38;5;66;03m# extract into pipeline schema\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1238\u001b[39m load_id = \u001b[43mextract\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_parallel_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_package_state_update\u001b[49m\u001b[43m=\u001b[49m\u001b[43mload_package_state_update\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[38;5;66;03m# update live schema but not update the store yet\u001b[39;00m\n\u001b[32m   1243\u001b[39m source.schema = \u001b[38;5;28mself\u001b[39m._schema_storage.set_live_schema(source.schema)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/extract/extract.py:435\u001b[39m, in \u001b[36mExtract.extract\u001b[39m\u001b[34m(self, source, max_parallel_items, workers, load_package_state_update)\u001b[39m\n\u001b[32m    432\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m resource.write_disposition == \u001b[33m\"\u001b[39m\u001b[33mreplace\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    433\u001b[39m                     reset_resource_state(resource.name)\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extract_single_source\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m            \u001b[49m\u001b[43mload_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m            \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_parallel_items\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_parallel_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m         commit_load_package_state()\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m load_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/extract/extract.py:358\u001b[39m, in \u001b[36mExtract._extract_single_source\u001b[39m\u001b[34m(self, load_id, source, max_parallel_items, workers)\u001b[39m\n\u001b[32m    356\u001b[39m left_gens = total_gens = \u001b[38;5;28mlen\u001b[39m(pipes._sources)\n\u001b[32m    357\u001b[39m collector.update(\u001b[33m\"\u001b[39m\u001b[33mResources\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m, total_gens)\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpipe_item\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpipes\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcurr_gens\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpipes\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_sources\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mleft_gens\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr_gens\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/extract/pipe_iterator.py:162\u001b[39m, in \u001b[36mPipeIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    158\u001b[39m pipe_item = \u001b[38;5;28mself\u001b[39m._futures_pool.resolve_next_future_no_wait()\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pipe_item \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# if none then take element from the newest source\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     pipe_item = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_source_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pipe_item \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Wait for some time for futures to resolve\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/dlt/extract/pipe_iterator.py:277\u001b[39m, in \u001b[36mPipeIterator._get_source_item\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    274\u001b[39m gen, step, pipe, meta = \u001b[38;5;28mself\u001b[39m._sources[\u001b[38;5;28mself\u001b[39m._current_source_index]\n\u001b[32m    275\u001b[39m set_current_pipe_name(pipe.name)\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m pipe_item = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pipe_item \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    279\u001b[39m     \u001b[38;5;66;03m# full pipe item may be returned, this is used by ForkPipe step\u001b[39;00m\n\u001b[32m    280\u001b[39m     \u001b[38;5;66;03m# to redirect execution of an item to another pipe\u001b[39;00m\n\u001b[32m    281\u001b[39m     \u001b[38;5;66;03m# else\u001b[39;00m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pipe_item, ResolvablePipeItem):\n\u001b[32m    283\u001b[39m         \u001b[38;5;66;03m# keep the item assigned step and pipe when creating resolvable item\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mkafka_voters_source\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Source function that reads voters from Kafka\"\"\"\u001b[39;00m\n\u001b[32m      9\u001b[39m consumer = KafkaConsumer(\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mvoters\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     11\u001b[39m     bootstrap_servers=[\u001b[33m'\u001b[39m\u001b[33mlocalhost:29092\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     group_id=\u001b[33m'\u001b[39m\u001b[33mdlt-voter-group\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     15\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconsumer\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/kafka/consumer/group.py:1188\u001b[39m, in \u001b[36mKafkaConsumer.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1186\u001b[39m     \u001b[38;5;28mself\u001b[39m._iterator = \u001b[38;5;28mself\u001b[39m._message_generator_v2()\n\u001b[32m   1187\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1188\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m   1190\u001b[39m     \u001b[38;5;28mself\u001b[39m._iterator = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/kafka/consumer/group.py:1160\u001b[39m, in \u001b[36mKafkaConsumer._message_generator_v2\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1158\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_message_generator_v2\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1159\u001b[39m     timeout_ms = \u001b[32m1000\u001b[39m * \u001b[38;5;28mmax\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mself\u001b[39m._consumer_timeout - time.time())\n\u001b[32m-> \u001b[39m\u001b[32m1160\u001b[39m     record_map = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1161\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m tp, records \u001b[38;5;129;01min\u001b[39;00m six.iteritems(record_map):\n\u001b[32m   1162\u001b[39m         \u001b[38;5;66;03m# Generators are stateful, and it is possible that the tp / records\u001b[39;00m\n\u001b[32m   1163\u001b[39m         \u001b[38;5;66;03m# here may become stale during iteration -- i.e., we seek to a\u001b[39;00m\n\u001b[32m   1164\u001b[39m         \u001b[38;5;66;03m# different offset, pause consumption, or lose assignment.\u001b[39;00m\n\u001b[32m   1165\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m records:\n\u001b[32m   1166\u001b[39m             \u001b[38;5;66;03m# is_fetchable(tp) should handle assignment changes and offset\u001b[39;00m\n\u001b[32m   1167\u001b[39m             \u001b[38;5;66;03m# resets; for all other changes (e.g., seeks) we'll rely on the\u001b[39;00m\n\u001b[32m   1168\u001b[39m             \u001b[38;5;66;03m# outer function destroying the existing iterator/generator\u001b[39;00m\n\u001b[32m   1169\u001b[39m             \u001b[38;5;66;03m# via self._iterator = None\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/kafka/consumer/group.py:693\u001b[39m, in \u001b[36mKafkaConsumer.poll\u001b[39m\u001b[34m(self, timeout_ms, max_records, update_offsets)\u001b[39m\n\u001b[32m    691\u001b[39m inner_timeout_ms = timeout_ms_fn(timeout_ms, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    692\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._closed:\n\u001b[32m--> \u001b[39m\u001b[32m693\u001b[39m     records = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_timeout_ms\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_records\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    694\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m records:\n\u001b[32m    695\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m records\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/kafka/consumer/group.py:736\u001b[39m, in \u001b[36mKafkaConsumer._poll_once\u001b[39m\u001b[34m(self, timeout_ms, max_records, update_offsets)\u001b[39m\n\u001b[32m    733\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m records:\n\u001b[32m    734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m records\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_timeout_ms\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_coordinator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtime_to_next_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[38;5;66;03m# after the long poll, we should check whether the group needs to rebalance\u001b[39;00m\n\u001b[32m    738\u001b[39m \u001b[38;5;66;03m# prior to returning data so that the group can stabilize faster\u001b[39;00m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._coordinator.need_rejoin():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/kafka/client_async.py:684\u001b[39m, in \u001b[36mKafkaClient.poll\u001b[39m\u001b[34m(self, timeout_ms, future)\u001b[39m\n\u001b[32m    677\u001b[39m         timeout = \u001b[38;5;28mmin\u001b[39m(\n\u001b[32m    678\u001b[39m             user_timeout_ms,\n\u001b[32m    679\u001b[39m             metadata_timeout_ms,\n\u001b[32m    680\u001b[39m             idle_connection_timeout_ms,\n\u001b[32m    681\u001b[39m             request_timeout_ms)\n\u001b[32m    682\u001b[39m         timeout = \u001b[38;5;28mmax\u001b[39m(\u001b[32m0\u001b[39m, timeout)  \u001b[38;5;66;03m# avoid negative timeouts\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[38;5;66;03m# called without the lock to avoid deadlock potential\u001b[39;00m\n\u001b[32m    687\u001b[39m \u001b[38;5;66;03m# if handlers need to acquire locks\u001b[39;00m\n\u001b[32m    688\u001b[39m responses.extend(\u001b[38;5;28mself\u001b[39m._fire_pending_completed_requests())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/kafka/client_async.py:727\u001b[39m, in \u001b[36mKafkaClient._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    724\u001b[39m \u001b[38;5;28mself\u001b[39m._register_send_sockets()\n\u001b[32m    726\u001b[39m start_select = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m727\u001b[39m ready = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    728\u001b[39m end_select = time.time()\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sensors:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/selectors.py:468\u001b[39m, in \u001b[36mEpollSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    466\u001b[39m ready = []\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    470\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from dlt.destinations import postgres\n",
    "destination_type, destination_config = get_destination_config()\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=pipeline_name,\n",
    "    destination=postgres(destination_config),\n",
    "    dataset_name='public',  # Use 'public' schema or whatever schema your tables are in\n",
    "    dev_mode=True  # This forces DLT to recreate all internal state tables\n",
    ")\n",
    "\n",
    "info = pipeline.run(\n",
    "        kafka_voters_source,\n",
    "        table_name=table_name,\n",
    "        write_disposition='append',\n",
    "        #merge_key=None,  # Set this to your primary key if you want upsert behavior\n",
    "        #if_exists='append'  # 'append' will add to existing tables, 'replace' would drop and recreate\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39abba72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
